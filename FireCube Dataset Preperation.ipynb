{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc6b9755-baea-4136-b6e5-edeb79e58e51",
   "metadata": {},
   "source": [
    "# Fire DataCube Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fe39d77-56ba-441d-b4be-d1d81026c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Optional, Union, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from rasterio.windows import bounds as window_bounds\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.mask import mask\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_reference_grid(\n",
    "    ca_boundary: str,\n",
    "    out_path: str,\n",
    "    dst_crs: str = \"EPSG:3310\",\n",
    "    dst_res: float = 100.0,\n",
    "    compress: str = \"lzw\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Create a reference grid that covers California at specified resolution.\n",
    "    This grid will be used to align ALL rasters (static and dynamic).\n",
    "    \n",
    "    Returns: path to the reference grid raster\n",
    "    \"\"\"\n",
    "    print(f\"[Creating Reference Grid]\")\n",
    "    ca = gpd.read_file(ca_boundary)\n",
    "    if ca.crs is None:\n",
    "        raise ValueError(\"CA boundary has no CRS\")\n",
    "    \n",
    "    ca = ca.to_crs(dst_crs)\n",
    "    bounds = ca.total_bounds  # minx, miny, maxx, maxy\n",
    "    \n",
    "    # Calculate dimensions\n",
    "    width = int(np.ceil((bounds[2] - bounds[0]) / dst_res))\n",
    "    height = int(np.ceil((bounds[3] - bounds[1]) / dst_res))\n",
    "    \n",
    "    # Create transform\n",
    "    from rasterio.transform import from_origin\n",
    "    transform = from_origin(bounds[0], bounds[3], dst_res, dst_res)\n",
    "    \n",
    "    # Create empty reference raster\n",
    "    profile = {\n",
    "        'driver': 'GTiff',\n",
    "        'height': height,\n",
    "        'width': width,\n",
    "        'count': 1,\n",
    "        'dtype': 'float32',\n",
    "        'crs': dst_crs,\n",
    "        'transform': transform,\n",
    "        'nodata': -9999.0,\n",
    "        'compress': compress\n",
    "    }\n",
    "    \n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    with rasterio.open(out_path, 'w', **profile) as dst:\n",
    "        dst.write(np.zeros((height, width), dtype='float32'), 1)\n",
    "    \n",
    "    print(f\"  ‚úì Reference grid created: {width}x{height} px at {dst_res}m resolution\")\n",
    "    print(f\"  ‚úì Saved to: {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def align_raster_to_reference(\n",
    "    src_raster: str,\n",
    "    reference_grid: str,\n",
    "    out_path: str,\n",
    "    ca_boundary: str,\n",
    "    compress: str = \"lzw\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Reproject and snap source raster to reference grid, then clip to CA boundary.\n",
    "    \"\"\"\n",
    "    print(f\"  Processing: {Path(src_raster).name}\")\n",
    "    \n",
    "    # Convert to Path object and create parent directories\n",
    "    out_path = Path(out_path)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Step 1: Reproject to match reference grid\n",
    "    with rasterio.open(reference_grid) as ref, rasterio.open(src_raster) as src:\n",
    "        profile = ref.profile.copy()\n",
    "        profile.update({'compress': compress})\n",
    "        \n",
    "        temp_path = str(out_path.parent / (out_path.name + \".temp.tif\"))\n",
    "        with rasterio.open(temp_path, 'w', **profile) as dst:\n",
    "            reproject(\n",
    "                source=rasterio.band(src, 1),\n",
    "                destination=rasterio.band(dst, 1),\n",
    "                src_transform=src.transform,\n",
    "                src_crs=src.crs,\n",
    "                dst_transform=ref.transform,\n",
    "                dst_crs=ref.crs,\n",
    "                resampling=Resampling.nearest,  # Use nearest for categorical data\n",
    "                src_nodata=src.nodata,\n",
    "                dst_nodata=ref.nodata\n",
    "            )\n",
    "    \n",
    "    # Step 2: Clip to CA boundary\n",
    "    ca = gpd.read_file(ca_boundary)\n",
    "    with rasterio.open(reference_grid) as ref:\n",
    "        if ca.crs != ref.crs:\n",
    "            ca = ca.to_crs(ref.crs)\n",
    "    \n",
    "    geoms = [geom.__geo_interface__ for geom in ca.geometry if geom is not None]\n",
    "    \n",
    "    with rasterio.open(temp_path) as src:\n",
    "        out_image, out_transform = mask(src, geoms, crop=True, nodata=src.nodata, filled=True)\n",
    "        out_meta = src.meta.copy()\n",
    "        out_meta.update({\n",
    "            \"height\": out_image.shape[1],\n",
    "            \"width\": out_image.shape[2],\n",
    "            \"transform\": out_transform,\n",
    "            \"compress\": compress\n",
    "        })\n",
    "        \n",
    "        with rasterio.open(str(out_path), \"w\", **out_meta) as dst:\n",
    "            dst.write(out_image)\n",
    "    \n",
    "    # Clean up temp file\n",
    "    if os.path.exists(temp_path):\n",
    "        os.remove(temp_path)\n",
    "    \n",
    "    print(f\"    ‚úì Aligned and clipped: {out_path.name}\")\n",
    "    return str(out_path)\n",
    "\n",
    "\n",
    "def discover_dynamic_rasters(\n",
    "    dynamic_folders: Dict[str, str],  # {variable_name: folder_path}\n",
    "    pattern: str = \"*.tif\"\n",
    ") -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Discover all .tif files in each dynamic variable folder.\n",
    "    \n",
    "    Args:\n",
    "        dynamic_folders: {variable_name: folder_path containing all tifs for that variable}\n",
    "        pattern: file pattern to match (default: \"*.tif\")\n",
    "    \n",
    "    Returns:\n",
    "        {variable_name: [sorted list of paths]}\n",
    "    \"\"\"\n",
    "    dynamic_rasters = {}\n",
    "    for var_name, folder_path in dynamic_folders.items():\n",
    "        folder = Path(folder_path)\n",
    "        if not folder.exists():\n",
    "            raise ValueError(f\"Folder not found: {folder_path}\")\n",
    "        \n",
    "        tif_files = sorted(folder.glob(pattern))\n",
    "        if not tif_files:\n",
    "            raise ValueError(f\"No .tif files found in {folder_path}\")\n",
    "        \n",
    "        dynamic_rasters[var_name] = [str(p) for p in tif_files]\n",
    "        print(f\"  {var_name}: found {len(tif_files)} files\")\n",
    "    \n",
    "    return dynamic_rasters\n",
    "\n",
    "\n",
    "def align_all_rasters(\n",
    "    static_rasters: Dict[str, str],  # {variable_name: path}\n",
    "    dynamic_rasters: Dict[str, List[str]],  # {variable_name: [path1, path2, ...]}\n",
    "    landcover_raster: Optional[str],  # NEW: landcover path\n",
    "    reference_grid: str,\n",
    "    ca_boundary: str,\n",
    "    out_root: str,\n",
    "    compress: str = \"lzw\",\n",
    "    skip_existing: bool = True  # Skip if aligned file already exists\n",
    ") -> Tuple[Dict[str, str], Dict[str, List[str]], Optional[str]]:\n",
    "    \"\"\"\n",
    "    Align all static, dynamic, and landcover rasters to the reference grid.\n",
    "    \n",
    "    Args:\n",
    "        landcover_raster: Path to landcover.tif (optional)\n",
    "        skip_existing: If True, skip alignment if output file already exists\n",
    "    \n",
    "    Returns:\n",
    "        (aligned_static_paths, aligned_dynamic_paths, aligned_landcover_path)\n",
    "    \"\"\"\n",
    "    print(\"\\n[Aligning Static Rasters]\")\n",
    "    aligned_static = {}\n",
    "    for var_name, src_path in static_rasters.items():\n",
    "        out_path = os.path.join(out_root, \"aligned_static\", f\"{var_name}_aligned.tif\")\n",
    "        \n",
    "        if skip_existing and os.path.exists(out_path):\n",
    "            print(f\"  ‚úì Using existing: {Path(out_path).name}\")\n",
    "            aligned_static[var_name] = out_path\n",
    "        else:\n",
    "            aligned_static[var_name] = align_raster_to_reference(\n",
    "                src_path, reference_grid, out_path, ca_boundary, compress\n",
    "            )\n",
    "    \n",
    "    # NEW: Align landcover\n",
    "    aligned_landcover = None\n",
    "    if landcover_raster and os.path.exists(landcover_raster):\n",
    "        print(\"\\n[Aligning Landcover Raster]\")\n",
    "        out_path = os.path.join(out_root, \"aligned_static\", \"landcover_aligned.tif\")\n",
    "        \n",
    "        if skip_existing and os.path.exists(out_path):\n",
    "            print(f\"  ‚úì Using existing: {Path(out_path).name}\")\n",
    "            aligned_landcover = out_path\n",
    "        else:\n",
    "            aligned_landcover = align_raster_to_reference(\n",
    "                landcover_raster, reference_grid, out_path, ca_boundary, compress\n",
    "            )\n",
    "    \n",
    "    print(\"\\n[Aligning Dynamic Rasters]\")\n",
    "    aligned_dynamic = {}\n",
    "    for var_name, src_paths in dynamic_rasters.items():\n",
    "        print(f\"\\n  Processing {var_name}: {len(src_paths)} files\")\n",
    "        aligned_dynamic[var_name] = []\n",
    "        \n",
    "        for src_path in tqdm(src_paths, desc=f\"  Aligning {var_name}\"):\n",
    "            # Extract date from filename\n",
    "            date_match = re.search(r'(\\d{8})', Path(src_path).stem)\n",
    "            date_str = date_match.group(1) if date_match else f\"t{len(aligned_dynamic[var_name]):06d}\"\n",
    "            \n",
    "            out_path = os.path.join(\n",
    "                out_root, \"aligned_dynamic\", var_name, f\"{var_name}_{date_str}_aligned.tif\"\n",
    "            )\n",
    "            \n",
    "            if skip_existing and os.path.exists(out_path):\n",
    "                aligned_dynamic[var_name].append(out_path)\n",
    "            else:\n",
    "                aligned_dynamic[var_name].append(\n",
    "                    align_raster_to_reference(src_path, reference_grid, out_path, ca_boundary, compress)\n",
    "                )\n",
    "    \n",
    "    return aligned_static, aligned_dynamic, aligned_landcover\n",
    "\n",
    "\n",
    "DATE8_RE = re.compile(r\"(?<!\\d)(\\d{8})(?!\\d)\")\n",
    "\n",
    "def parse_date_from_path(raster_path: str) -> Optional[datetime]:\n",
    "    \"\"\"Extract date from filename (YYYYMMDD format)\"\"\"\n",
    "    m = DATE8_RE.search(Path(raster_path).stem)\n",
    "    if m:\n",
    "        try:\n",
    "            return datetime.strptime(m.group(1), \"%Y%m%d\")\n",
    "        except:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "\n",
    "def one_hot_encode_landcover(landcover_patch: np.ndarray, num_classes: int = 10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert landcover patch to one-hot encoded format.\n",
    "    \n",
    "    Args:\n",
    "        landcover_patch: 2D array with landcover classes (1-10)\n",
    "        num_classes: Number of landcover classes (default: 10)\n",
    "    \n",
    "    Returns:\n",
    "        3D array of shape (num_classes, height, width) with binary values\n",
    "    \"\"\"\n",
    "    height, width = landcover_patch.shape\n",
    "    one_hot = np.zeros((num_classes, height, width), dtype=np.float32)\n",
    "    \n",
    "    valid_mask = ~np.isnan(landcover_patch)\n",
    "    \n",
    "    for class_id in range(1, num_classes + 1):\n",
    "        class_mask = (landcover_patch == class_id) & valid_mask\n",
    "        one_hot[class_id - 1] = class_mask.astype(np.float32)\n",
    "    \n",
    "    return one_hot\n",
    "\n",
    "\n",
    "def build_aligned_fire_dataset(\n",
    "    aligned_static: Dict[str, str],  # {var_name: aligned_path}\n",
    "    aligned_dynamic: Dict[str, List[str]],  # {var_name: [aligned_paths]}\n",
    "    aligned_landcover: Optional[str],  # NEW: aligned landcover path\n",
    "    fire_dataset: str,\n",
    "    fire_date_field: str,\n",
    "    ca_boundary: str,\n",
    "    out_root: str = \"output_aligned_fire_patches\",\n",
    "    tile_size: int = 25,\n",
    "    window_days: int = 10,\n",
    "    min_pos_frac: float = 0.80,\n",
    "    min_valid_frac: float = 0.50,\n",
    "    require_all_valid: bool = True,\n",
    "    strict_inside: bool = True,\n",
    "    num_landcover_classes: int = 10, \n",
    "    write_individual_static_tifs: bool = True,\n",
    "    write_individual_dynamic_tifs_days: int = 2,\n",
    "    write_individual_landcover_tifs: bool = True,\n",
    "    tif_compress: str = \"lzw\",\n",
    "    tif_nodata: float = -9999.0,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create aligned .npy patches for static, dynamic, and landcover data.\n",
    "    \n",
    "    NEW: Landcover is one-hot encoded to shape (num_classes, tile_size, tile_size)\n",
    "    \n",
    "    Output files:\n",
    "      ‚Ä¢ Static NPY:     YYYYMMDD_row_col_static.npy\n",
    "      ‚Ä¢ Dynamic NPY:    YYYYMMDD_row_col_dynamic.npy\n",
    "      ‚Ä¢ Landcover NPY:  YYYYMMDD_row_col_clc_vec.npy  (one-hot encoded)\n",
    "    \"\"\"\n",
    "    from rasterio.windows import transform as window_transform\n",
    "\n",
    "    out_root = Path(out_root)\n",
    "    out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Reference from first static raster\n",
    "    ref_path = next(iter(aligned_static.values()))\n",
    "    with rasterio.open(ref_path) as ref:\n",
    "        ref_crs = ref.crs\n",
    "        ref_transform = ref.transform\n",
    "        ref_height = ref.height\n",
    "        ref_width = ref.width\n",
    "\n",
    "    print(f\"\\n[Reference Grid] {ref_width}x{ref_height} px\")\n",
    "\n",
    "    # Boundary\n",
    "    ca = gpd.read_file(ca_boundary)\n",
    "    if ca.crs != ref_crs:\n",
    "        ca = ca.to_crs(ref_crs)\n",
    "    ca_union = ca.union_all()\n",
    "\n",
    "    # Fires\n",
    "    print(\"\\n[Loading Fire Dataset]\")\n",
    "    fires = gpd.read_file(fire_dataset)\n",
    "    if fires.crs != ref_crs:\n",
    "        fires = fires.to_crs(ref_crs)\n",
    "    if fire_date_field not in fires.columns:\n",
    "        raise ValueError(f\"Fire date field '{fire_date_field}' not found\")\n",
    "\n",
    "    def _pfd(v):\n",
    "        if pd.isna(v): return None\n",
    "        try: return pd.to_datetime(str(v)).date()\n",
    "        except: return None\n",
    "\n",
    "    fires['__fire_date__'] = fires[fire_date_field].apply(_pfd)\n",
    "    fires = fires.dropna(subset=['__fire_date__'])\n",
    "    fires_by_date = {d: grp for d, grp in fires.groupby('__fire_date__')}\n",
    "    print(f\"  ‚úì Found {len(fires)} fire polygons across {len(fires_by_date)} unique dates\")\n",
    "\n",
    "    # Dynamic index\n",
    "    print(\"\\n[Indexing Dynamic Rasters]\")\n",
    "    dynamic_index = {}\n",
    "    for var_name, paths in aligned_dynamic.items():\n",
    "        dynamic_index[var_name] = {}\n",
    "        for p in paths:\n",
    "            dt = parse_date_from_path(p)\n",
    "            if dt:\n",
    "                dynamic_index[var_name][dt.date()] = p\n",
    "        print(f\"  {var_name}: {len(dynamic_index[var_name])} dates\")\n",
    "\n",
    "    # Date intersection across dynamic vars\n",
    "    all_dates = set.intersection(*[set(d.keys()) for d in dynamic_index.values()])\n",
    "    all_dates = sorted(all_dates)\n",
    "    print(f\"  ‚úì {len(all_dates)} dates available across all dynamic variables\")\n",
    "\n",
    "    # Output dirs\n",
    "    # static_dir = out_root / \"static_patches\"\n",
    "    # dynamic_dir = out_root / \"dynamic_patches\"\n",
    "    # landcover_dir = out_root / \"landcover_patches\"  # NEW\n",
    "    # static_dir.mkdir(exist_ok=True)\n",
    "    # dynamic_dir.mkdir(exist_ok=True)\n",
    "    # landcover_dir.mkdir(exist_ok=True)\n",
    "    npy_dir = Path(out_root) / \"positive\"\n",
    "    npy_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Individual per-variable GeoTIFF dirs\n",
    "    static_tif_root = out_root / \"static_tifs\"\n",
    "    dynamic_tif_root = out_root / \"dynamic_tifs\"\n",
    "    landcover_tif_root = out_root / \"landcover_tifs\"  # NEW\n",
    "    \n",
    "    if write_individual_static_tifs:\n",
    "        static_tif_root.mkdir(exist_ok=True)\n",
    "    if write_individual_dynamic_tifs_days and write_individual_dynamic_tifs_days > 0:\n",
    "        dynamic_tif_root.mkdir(exist_ok=True)\n",
    "    if write_individual_landcover_tifs and aligned_landcover:\n",
    "        landcover_tif_root.mkdir(exist_ok=True)\n",
    "\n",
    "    manifest_rows = []\n",
    "    patch_id = 0\n",
    "\n",
    "    static_vars = sorted(aligned_static.keys())\n",
    "    dynamic_vars = sorted(aligned_dynamic.keys())\n",
    "\n",
    "    print(f\"\\n[Extracting Patches]\")\n",
    "    print(f\"  Static variables: {static_vars}\")\n",
    "    print(f\"  Dynamic variables: {dynamic_vars}\")\n",
    "    print(f\"  Landcover classes: {num_landcover_classes if aligned_landcover else 'N/A'}\")\n",
    "    print(f\"  Window days: {window_days}\")\n",
    "\n",
    "    for T in tqdm(all_dates, desc=\"Processing dates\"):\n",
    "        fires_T = fires_by_date.get(T)\n",
    "        if fires_T is None or fires_T.empty:\n",
    "            continue\n",
    "\n",
    "        sindex = fires_T.sindex\n",
    "\n",
    "        needed_dates = [T - timedelta(days=i) for i in range(window_days)]\n",
    "        if not all(d in all_dates for d in needed_dates):\n",
    "            continue\n",
    "\n",
    "        rows = range(0, ref_height - (ref_height % tile_size), tile_size)\n",
    "        cols = range(0, ref_width - (ref_width % tile_size), tile_size)\n",
    "\n",
    "        for r0 in rows:\n",
    "            for c0 in cols:\n",
    "                win = Window(col_off=c0, row_off=r0, width=tile_size, height=tile_size)\n",
    "                left, bottom, right, top = window_bounds(win, transform=ref_transform)\n",
    "                tile_poly = box(left, bottom, right, top)\n",
    "\n",
    "                if strict_inside and not ca_union.covers(tile_poly):\n",
    "                    continue\n",
    "\n",
    "                cand_idx = list(sindex.intersection(tile_poly.bounds))\n",
    "                if not cand_idx:\n",
    "                    continue\n",
    "\n",
    "                inter_area = 0.0\n",
    "                for geom in fires_T.geometry.iloc[cand_idx]:\n",
    "                    if geom is None or geom.is_empty:\n",
    "                        continue\n",
    "                    try:\n",
    "                        inter_area += geom.intersection(tile_poly).area\n",
    "                    except Exception:\n",
    "                        inter_area += geom.buffer(0).intersection(tile_poly).area\n",
    "\n",
    "                tile_area = tile_poly.area\n",
    "                overlap_frac = inter_area / tile_area if tile_area > 0 else 0.0\n",
    "                if overlap_frac < min_pos_frac:\n",
    "                    continue\n",
    "\n",
    "                # --- Static stack ---\n",
    "                static_stack = []\n",
    "                valid_static = True\n",
    "                for var_name in static_vars:\n",
    "                    with rasterio.open(aligned_static[var_name]) as src:\n",
    "                        patch = src.read(1, window=win, masked=True)\n",
    "                        if patch.shape != (tile_size, tile_size):\n",
    "                            valid_static = False; break\n",
    "                        invalid = patch.mask\n",
    "                        if require_all_valid and invalid.any():\n",
    "                            valid_static = False; break\n",
    "                        elif not require_all_valid:\n",
    "                            valid_frac = 1.0 - float(invalid.mean())\n",
    "                            if valid_frac < min_valid_frac:\n",
    "                                valid_static = False; break\n",
    "                        arr = np.asarray(patch, dtype=np.float32)\n",
    "                        if invalid.any():\n",
    "                            arr = np.where(invalid, np.nan, arr)\n",
    "                        static_stack.append(arr)\n",
    "                if not valid_static:\n",
    "                    continue\n",
    "\n",
    "                # --- Landcover (one-hot encoded) ---\n",
    "                landcover_array = None\n",
    "                if aligned_landcover:\n",
    "                    with rasterio.open(aligned_landcover) as src:\n",
    "                        lc_patch = src.read(1, window=win, masked=True)\n",
    "                        if lc_patch.shape != (tile_size, tile_size):\n",
    "                            continue\n",
    "                        \n",
    "                        # Convert to float and handle nodata\n",
    "                        lc_arr = np.asarray(lc_patch, dtype=np.float32)\n",
    "                        if lc_patch.mask.any():\n",
    "                            lc_arr = np.where(lc_patch.mask, np.nan, lc_arr)\n",
    "                        \n",
    "                        # One-hot encode\n",
    "                        landcover_array = one_hot_encode_landcover(lc_arr, num_landcover_classes)\n",
    "\n",
    "                # --- Dynamic stack ---\n",
    "                dynamic_stack = []\n",
    "                valid_dynamic = True\n",
    "                for date_offset in range(window_days):\n",
    "                    target_date = T - timedelta(days=date_offset)\n",
    "                    day_stack = []\n",
    "                    for var_name in dynamic_vars:\n",
    "                        raster_path = dynamic_index[var_name][target_date]\n",
    "                        with rasterio.open(raster_path) as src:\n",
    "                            patch = src.read(1, window=win, masked=True)\n",
    "                            if patch.shape != (tile_size, tile_size):\n",
    "                                valid_dynamic = False; break\n",
    "                            invalid = patch.mask\n",
    "                            if require_all_valid and invalid.any():\n",
    "                                valid_dynamic = False; break\n",
    "                            elif not require_all_valid:\n",
    "                                valid_frac = 1.0 - float(invalid.mean())\n",
    "                                if valid_frac < min_valid_frac:\n",
    "                                    valid_dynamic = False; break\n",
    "                            arr = np.asarray(patch, dtype=np.float32)\n",
    "                            if invalid.any():\n",
    "                                arr = np.where(invalid, np.nan, arr)\n",
    "                            day_stack.append(arr)\n",
    "                    if not valid_dynamic:\n",
    "                        break\n",
    "                    dynamic_stack.append(np.stack(day_stack, axis=0))\n",
    "                if not valid_dynamic:\n",
    "                    continue\n",
    "\n",
    "                # --- Save NPYs ---\n",
    "                patch_id += 1\n",
    "                fire_day_str = T.strftime(\"%Y%m%d\")\n",
    "                static_array = np.stack(static_stack, axis=0)\n",
    "                dynamic_array = np.stack(dynamic_stack, axis=0)\n",
    "\n",
    "                static_path = npy_dir / f\"{fire_day_str}_{int(r0)}_{int(c0)}_static.npy\"\n",
    "                dynamic_path = npy_dir / f\"{fire_day_str}_{int(r0)}_{int(c0)}_dynamic.npy\"\n",
    "                np.save(static_path, static_array.astype(np.float32))\n",
    "                np.save(dynamic_path, dynamic_array.astype(np.float32))\n",
    "                \n",
    "                # NEW: Save landcover as clc_vec.npy\n",
    "                landcover_path = None\n",
    "                if landcover_array is not None:\n",
    "                    landcover_path = npy_dir / f\"{fire_day_str}_{int(r0)}_{int(c0)}_clc_vec.npy\"\n",
    "                    np.save(landcover_path, landcover_array.astype(np.float32))\n",
    "\n",
    "                # --- Write individual GeoTIFFs ---\n",
    "                tile_transform = window_transform(win, ref_transform)\n",
    "\n",
    "                # 1) Static TIFs\n",
    "                if write_individual_static_tifs:\n",
    "                    for idx, var_name in enumerate(static_vars):\n",
    "                        arr = static_array[idx]\n",
    "                        var_dir = (static_tif_root / var_name)\n",
    "                        var_dir.mkdir(parents=True, exist_ok=True)\n",
    "                        out_tif = var_dir / f\"{fire_day_str}_{int(r0)}_{int(c0)}_static.tif\"\n",
    "                        profile = {\n",
    "                            \"driver\": \"GTiff\",\n",
    "                            \"height\": tile_size,\n",
    "                            \"width\": tile_size,\n",
    "                            \"count\": 1,\n",
    "                            \"dtype\": \"float32\",\n",
    "                            \"crs\": ref_crs,\n",
    "                            \"transform\": tile_transform,\n",
    "                            \"nodata\": tif_nodata,\n",
    "                            \"compress\": tif_compress,\n",
    "                        }\n",
    "                        with rasterio.open(out_tif, \"w\", **profile) as dst:\n",
    "                            dst.write(np.where(np.isnan(arr), tif_nodata, arr).astype(np.float32), 1)\n",
    "                            dst.update_tags(\n",
    "                                patch_id=int(patch_id),\n",
    "                                fire_date=str(T),\n",
    "                                row_off=int(r0),\n",
    "                                col_off=int(c0),\n",
    "                                var_name=var_name,\n",
    "                            )\n",
    "\n",
    "                # 2) Dynamic TIFs (first K days)\n",
    "                K = max(0, min(int(write_individual_dynamic_tifs_days), window_days))\n",
    "                for d in range(K):\n",
    "                    day_date = (T - timedelta(days=d)).strftime(\"%Y%m%d\")\n",
    "                    for vidx, var_name in enumerate(dynamic_vars):\n",
    "                        arr = dynamic_array[d, vidx]\n",
    "                        var_dir = (dynamic_tif_root / var_name)\n",
    "                        var_dir.mkdir(parents=True, exist_ok=True)\n",
    "                        out_tif = var_dir / f\"{day_date}_{int(r0)}_{int(c0)}_dynamic.tif\"\n",
    "                        profile = {\n",
    "                            \"driver\": \"GTiff\",\n",
    "                            \"height\": tile_size,\n",
    "                            \"width\": tile_size,\n",
    "                            \"count\": 1,\n",
    "                            \"dtype\": \"float32\",\n",
    "                            \"crs\": ref_crs,\n",
    "                            \"transform\": tile_transform,\n",
    "                            \"nodata\": tif_nodata,\n",
    "                            \"compress\": tif_compress,\n",
    "                        }\n",
    "                        with rasterio.open(out_tif, \"w\", **profile) as dst:\n",
    "                            dst.write(np.where(np.isnan(arr), tif_nodata, arr).astype(np.float32), 1)\n",
    "                            dst.update_tags(\n",
    "                                patch_id=int(patch_id),\n",
    "                                fire_date=str(T),\n",
    "                                day_index=int(d),\n",
    "                                day_date=day_date,\n",
    "                                row_off=int(r0),\n",
    "                                col_off=int(c0),\n",
    "                                var_name=var_name,\n",
    "                            )\n",
    "\n",
    "                # 3) NEW: Landcover TIFs (one per class)\n",
    "                if write_individual_landcover_tifs and landcover_array is not None:\n",
    "                    for class_id in range(num_landcover_classes):\n",
    "                        arr = landcover_array[class_id]\n",
    "                        class_name = f\"class_{class_id + 1}\"\n",
    "                        var_dir = (landcover_tif_root / class_name)\n",
    "                        var_dir.mkdir(parents=True, exist_ok=True)\n",
    "                        out_tif = var_dir / f\"{fire_day_str}_{int(r0)}_{int(c0)}_clc_vec.tif\"\n",
    "                        profile = {\n",
    "                            \"driver\": \"GTiff\",\n",
    "                            \"height\": tile_size,\n",
    "                            \"width\": tile_size,\n",
    "                            \"count\": 1,\n",
    "                            \"dtype\": \"float32\",\n",
    "                            \"crs\": ref_crs,\n",
    "                            \"transform\": tile_transform,\n",
    "                            \"nodata\": tif_nodata,\n",
    "                            \"compress\": tif_compress,\n",
    "                        }\n",
    "                        with rasterio.open(out_tif, \"w\", **profile) as dst:\n",
    "                            dst.write(arr.astype(np.float32), 1)\n",
    "                            dst.update_tags(\n",
    "                                patch_id=int(patch_id),\n",
    "                                fire_date=str(T),\n",
    "                                row_off=int(r0),\n",
    "                                col_off=int(c0),\n",
    "                                landcover_class=int(class_id + 1),\n",
    "                            )\n",
    "\n",
    "                # Manifest\n",
    "                manifest_row = {\n",
    "                    'patch_id': patch_id,\n",
    "                    'static_path': str(static_path),\n",
    "                    'dynamic_path': str(dynamic_path),\n",
    "                    'fire_date': T.strftime('%Y-%m-%d'),\n",
    "                    'row_off': r0,\n",
    "                    'col_off': c0,\n",
    "                    'left': left,\n",
    "                    'bottom': bottom,\n",
    "                    'right': right,\n",
    "                    'top': top,\n",
    "                    'overlap_frac': overlap_frac,\n",
    "                    'static_vars': ','.join(static_vars),\n",
    "                    'dynamic_vars': ','.join(dynamic_vars),\n",
    "                    'window_days': window_days,\n",
    "                }\n",
    "                if landcover_path:\n",
    "                    manifest_row['landcover_path'] = str(landcover_path)\n",
    "                    manifest_row['landcover_classes'] = num_landcover_classes\n",
    "                \n",
    "                manifest_rows.append(manifest_row)\n",
    "\n",
    "    # Save manifest\n",
    "    manifest = pd.DataFrame(manifest_rows)\n",
    "    manifest_path = out_root / \"aligned_patches_manifest.csv\"\n",
    "    manifest.to_csv(manifest_path, index=False)\n",
    "\n",
    "    print(f\"\\n‚úÖ Complete!\")\n",
    "    print(f\"  Total patches: {len(manifest)}\")\n",
    "    print(f\"  Static shape: ({len(static_vars)}, {tile_size}, {tile_size})\")\n",
    "    print(f\"  Dynamic shape: ({window_days}, {len(dynamic_vars)}, {tile_size}, {tile_size})\")\n",
    "    if aligned_landcover:\n",
    "        print(f\"  Landcover shape: ({num_landcover_classes}, {tile_size}, {tile_size}) [one-hot encoded]\")\n",
    "    print(f\"  Manifest: {manifest_path}\")\n",
    "    print(f\"  Static TIFs: {static_tif_root if write_individual_static_tifs else 'disabled'}\")\n",
    "    print(f\"  Dynamic TIFs (first {write_individual_dynamic_tifs_days} days): \"\n",
    "          f\"{dynamic_tif_root if write_individual_dynamic_tifs_days>0 else 'disabled'}\")\n",
    "    if aligned_landcover:\n",
    "        print(f\"  Landcover TIFs: {landcover_tif_root if write_individual_landcover_tifs else 'disabled'}\")\n",
    "\n",
    "    return manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a908868c-7781-47bc-b2b7-2b40296e1a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ALIGNED FIRE DATASET BUILDER\n",
      "======================================================================\n",
      "\n",
      "[Step 0: Discovering Dynamic Rasters]\n",
      "  relative_humidity: found 3656 files\n",
      "  total_precipitation: found 3653 files\n",
      "\n",
      "‚úì Total dynamic files found: 7309\n",
      "\n",
      "[Step 1: Creating Reference Grid]\n",
      "  ‚úì Using existing reference grid: Dataset/Stataic Data/rasters_COP90/elevation_fixed_3310_1000m_clipped.tif\n",
      "\n",
      "[Step 2: Aligning Rasters]\n",
      "‚ö†Ô∏è  This may take a while with ~3,650 dynamic files (10 years √ó 365 days)\n",
      "    Set skip_existing_aligned=True to skip already processed files\n",
      "\n",
      "[Aligning Static Rasters]\n",
      "  ‚úì Using existing: elevation_aligned.tif\n",
      "  ‚úì Using existing: slope_aligned.tif\n",
      "  ‚úì Using existing: population_aligned.tif\n",
      "  ‚úì Using existing: water_proximity_aligned.tif\n",
      "  ‚úì Using existing: road_proximity_aligned.tif\n",
      "\n",
      "[Aligning Landcover Raster]\n",
      "  ‚úì Using existing: landcover_aligned.tif\n",
      "\n",
      "[Aligning Dynamic Rasters]\n",
      "\n",
      "  Processing relative_humidity: 3656 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Aligning relative_humidity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3656/3656 [00:00<00:00, 97019.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Processing total_precipitation: 3653 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Aligning total_precipitation: 100%|‚ñà‚ñà‚ñà‚ñà| 3653/3653 [00:00<00:00, 98383.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Alignment complete\n",
      "  Static: 5 variables\n",
      "  Dynamic: 7309 files across 2 variables\n",
      "\n",
      "[Step 3: Extracting Aligned Fire Patches]\n",
      "  This will create .npy files for patches that overlap with fires\n",
      "\n",
      "[Reference Grid] 915x1056 px\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_3808/510207535.py:322: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  ca_union = ca.unary_union\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Loading Fire Dataset]\n",
      "  ‚úì Found 4032 fire polygons across 1671 unique dates\n",
      "\n",
      "[Indexing Dynamic Rasters]\n",
      "  relative_humidity: 3653 dates\n",
      "  total_precipitation: 3653 dates\n",
      "  ‚úì 3653 dates available across all dynamic variables\n",
      "\n",
      "[Extracting Patches]\n",
      "  Static variables: ['elevation', 'population', 'road_proximity', 'slope', 'water_proximity']\n",
      "  Dynamic variables: ['relative_humidity', 'total_precipitation']\n",
      "  Landcover classes: 10\n",
      "  Window days: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dates: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3653/3653 [1:27:23<00:00,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Complete!\n",
      "  Total patches: 4996\n",
      "  Static shape: (5, 4, 4)\n",
      "  Dynamic shape: (10, 2, 4, 4)\n",
      "  Landcover shape: (10, 4, 4) [one-hot encoded]\n",
      "  Manifest: output_aligned_patches/aligned_patches_manifest.csv\n",
      "  Static TIFs: output_aligned_patches/static_tifs\n",
      "  Dynamic TIFs (first 2 days): output_aligned_patches/dynamic_tifs\n",
      "  Landcover TIFs: output_aligned_patches/landcover_tifs\n",
      "\n",
      "======================================================================\n",
      "üìä SUMMARY\n",
      "======================================================================\n",
      "Total fire patches extracted: 4996\n",
      "\n",
      "Static patch shape: (5, 4, 4)\n",
      "Dynamic patch shape: (10, 2, 4, 4)\n",
      "\n",
      "Output directory: output_aligned_patches\n",
      "Manifest file: output_aligned_patches/aligned_patches_manifest.csv\n",
      "\n",
      "üìù First few patches:\n",
      "   patch_id                                        static_path  \\\n",
      "0         1  output_aligned_patches/positive/20150206_424_4...   \n",
      "1         2  output_aligned_patches/positive/20150207_504_4...   \n",
      "2         3  output_aligned_patches/positive/20150207_508_4...   \n",
      "3         4  output_aligned_patches/positive/20150207_508_4...   \n",
      "4         5  output_aligned_patches/positive/20150418_904_5...   \n",
      "5         6  output_aligned_patches/positive/20150609_148_7...   \n",
      "6         7  output_aligned_patches/positive/20150609_148_7...   \n",
      "7         8  output_aligned_patches/positive/20150617_868_6...   \n",
      "8         9  output_aligned_patches/positive/20150617_868_6...   \n",
      "9        10  output_aligned_patches/positive/20150617_872_6...   \n",
      "\n",
      "                                        dynamic_path   fire_date  row_off  \\\n",
      "0  output_aligned_patches/positive/20150206_424_4...  2015-02-06      424   \n",
      "1  output_aligned_patches/positive/20150207_504_4...  2015-02-07      504   \n",
      "2  output_aligned_patches/positive/20150207_508_4...  2015-02-07      508   \n",
      "3  output_aligned_patches/positive/20150207_508_4...  2015-02-07      508   \n",
      "4  output_aligned_patches/positive/20150418_904_5...  2015-04-18      904   \n",
      "5  output_aligned_patches/positive/20150609_148_7...  2015-06-09      148   \n",
      "6  output_aligned_patches/positive/20150609_148_7...  2015-06-09      148   \n",
      "7  output_aligned_patches/positive/20150617_868_6...  2015-06-17      868   \n",
      "8  output_aligned_patches/positive/20150617_868_6...  2015-06-17      868   \n",
      "9  output_aligned_patches/positive/20150617_872_6...  2015-06-17      872   \n",
      "\n",
      "   col_off           left         bottom          right            top  \\\n",
      "0      440   65572.789156   22494.774275   69572.789156   26494.774275   \n",
      "1      492  117572.789156  -57505.225725  121572.789156  -53505.225725   \n",
      "2      492  117572.789156  -61505.225725  121572.789156  -57505.225725   \n",
      "3      496  121572.789156  -61505.225725  125572.789156  -57505.225725   \n",
      "4      592  217572.789156 -457505.225725  221572.789156 -453505.225725   \n",
      "5       72 -302427.210844  298494.774275 -298427.210844  302494.774275   \n",
      "6       76 -298427.210844  298494.774275 -294427.210844  302494.774275   \n",
      "7      676  301572.789156 -421505.225725  305572.789156 -417505.225725   \n",
      "8      680  305572.789156 -421505.225725  309572.789156 -417505.225725   \n",
      "9      660  285572.789156 -425505.225725  289572.789156 -421505.225725   \n",
      "\n",
      "   overlap_frac                                        static_vars  \\\n",
      "0      0.127062  elevation,population,road_proximity,slope,wate...   \n",
      "1      0.729790  elevation,population,road_proximity,slope,wate...   \n",
      "2      0.472926  elevation,population,road_proximity,slope,wate...   \n",
      "3      0.363705  elevation,population,road_proximity,slope,wate...   \n",
      "4      0.175638  elevation,population,road_proximity,slope,wate...   \n",
      "5      0.131547  elevation,population,road_proximity,slope,wate...   \n",
      "6      0.126550  elevation,population,road_proximity,slope,wate...   \n",
      "7      0.271704  elevation,population,road_proximity,slope,wate...   \n",
      "8      0.852529  elevation,population,road_proximity,slope,wate...   \n",
      "9      0.399684  elevation,population,road_proximity,slope,wate...   \n",
      "\n",
      "                            dynamic_vars  window_days  \\\n",
      "0  relative_humidity,total_precipitation           10   \n",
      "1  relative_humidity,total_precipitation           10   \n",
      "2  relative_humidity,total_precipitation           10   \n",
      "3  relative_humidity,total_precipitation           10   \n",
      "4  relative_humidity,total_precipitation           10   \n",
      "5  relative_humidity,total_precipitation           10   \n",
      "6  relative_humidity,total_precipitation           10   \n",
      "7  relative_humidity,total_precipitation           10   \n",
      "8  relative_humidity,total_precipitation           10   \n",
      "9  relative_humidity,total_precipitation           10   \n",
      "\n",
      "                                      landcover_path  landcover_classes  \n",
      "0  output_aligned_patches/positive/20150206_424_4...                 10  \n",
      "1  output_aligned_patches/positive/20150207_504_4...                 10  \n",
      "2  output_aligned_patches/positive/20150207_508_4...                 10  \n",
      "3  output_aligned_patches/positive/20150207_508_4...                 10  \n",
      "4  output_aligned_patches/positive/20150418_904_5...                 10  \n",
      "5  output_aligned_patches/positive/20150609_148_7...                 10  \n",
      "6  output_aligned_patches/positive/20150609_148_7...                 10  \n",
      "7  output_aligned_patches/positive/20150617_868_6...                 10  \n",
      "8  output_aligned_patches/positive/20150617_868_6...                 10  \n",
      "9  output_aligned_patches/positive/20150617_872_6...                 10  \n",
      "\n",
      "üìÖ Date range:\n",
      "  Earliest: 2015-02-06\n",
      "  Latest: 2024-12-09\n",
      "\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'ca_boundary': 'Dataset/Stataic Data/CA_State.gpkg',\n",
    "    'fire_dataset': 'Dataset/Stataic Data/past_fire_2014_2024.gpkg',\n",
    "    'fire_date_field': 'ALARM_DATE',\n",
    "    \n",
    "    'static_rasters': {\n",
    "        'elevation': 'Dataset/Stataic Data/rasters_COP90/output_hh.tif',\n",
    "        'slope': 'Dataset/Stataic Data/viz/Slope.tif',\n",
    "        'population': 'Dataset/Stataic Data/Population/mosaic_masked.tif',\n",
    "        'water_proximity': 'Dataset/Stataic Data/Waterway/ca_water_distance.tif',\n",
    "        'road_proximity': 'Dataset/Stataic Data/roadways/ca_road_distance_snapped.tif',\n",
    "    },\n",
    "    'dynamic_folders': {\n",
    "        'relative_humidity': 'Dataset/Dynamic Data/relative_humidity',\n",
    "        'total_precipitation': 'Dataset/Dynamic Data/Precipitation',\n",
    "    },\n",
    "    'reference_grid_path': 'Dataset/Stataic Data/rasters_COP90/elevation_fixed_3310_1000m_clipped.tif',\n",
    "    'out_root': 'output_aligned_patches',\n",
    "    'tile_size': 4,\n",
    "    'window_days': 10,  \n",
    "    'dst_crs': 'EPSG:3310',\n",
    "    'dst_res': 1000.0,  \n",
    "    'skip_existing_aligned': True,  \n",
    "    'min_pos_frac': 0.10,  \n",
    "    'require_all_valid': False,\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ALIGNED FIRE DATASET BUILDER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[Step 0: Discovering Dynamic Rasters]\")\n",
    "dynamic_rasters = discover_dynamic_rasters(\n",
    "    dynamic_folders=config['dynamic_folders'],\n",
    "    pattern=\"*.tif\"\n",
    ")\n",
    "print(f\"\\n‚úì Total dynamic files found: {sum(len(files) for files in dynamic_rasters.values())}\")\n",
    "\n",
    "print(\"\\n[Step 1: Creating Reference Grid]\")\n",
    "if os.path.exists(config['reference_grid_path']):\n",
    "    print(f\"  ‚úì Using existing reference grid: {config['reference_grid_path']}\")\n",
    "    ref_grid = config['reference_grid_path']\n",
    "else:\n",
    "    ref_grid = create_reference_grid(\n",
    "        ca_boundary=config['ca_boundary'],\n",
    "        out_path=config['reference_grid_path'],\n",
    "        dst_crs=config['dst_crs'],\n",
    "        dst_res=config['dst_res']\n",
    "    )\n",
    "\n",
    "print(\"\\n[Step 2: Aligning Rasters]\")\n",
    "print(\"‚ö†Ô∏è  This may take a while with ~3,650 dynamic files (10 years √ó 365 days)\")\n",
    "print(\"    Set skip_existing_aligned=True to skip already processed files\")\n",
    "\n",
    "aligned_static, aligned_dynamic, aligned_landcover = align_all_rasters(\n",
    "    static_rasters=config['static_rasters'],\n",
    "    landcover_raster = \"Dataset/Stataic Data/LandCover/land_cover_cal_reclass.tif\",\n",
    "    dynamic_rasters=dynamic_rasters,\n",
    "    reference_grid=ref_grid,\n",
    "    ca_boundary=config['ca_boundary'],\n",
    "    out_root=config['out_root'],\n",
    "    skip_existing=config['skip_existing_aligned']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Alignment complete\")\n",
    "print(f\"  Static: {len(aligned_static)} variables\")\n",
    "print(f\"  Dynamic: {sum(len(files) for files in aligned_dynamic.values())} files across {len(aligned_dynamic)} variables\")\n",
    "\n",
    "print(\"\\n[Step 3: Extracting Aligned Fire Patches]\")\n",
    "print(\"  This will create .npy files for patches that overlap with fires\")\n",
    "\n",
    "manifest = build_aligned_fire_dataset(\n",
    "    aligned_static=aligned_static,\n",
    "    aligned_dynamic=aligned_dynamic,\n",
    "    aligned_landcover = aligned_landcover,\n",
    "    fire_dataset=config['fire_dataset'],\n",
    "    fire_date_field=config['fire_date_field'],\n",
    "    ca_boundary=config['ca_boundary'],\n",
    "    out_root=config['out_root'],\n",
    "    tile_size=config['tile_size'],\n",
    "    window_days=config['window_days'],\n",
    "    min_pos_frac=config['min_pos_frac'],\n",
    "    require_all_valid=config['require_all_valid']\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total fire patches extracted: {len(manifest)}\")\n",
    "print(f\"\\nStatic patch shape: ({len(aligned_static)}, {config['tile_size']}, {config['tile_size']})\")\n",
    "print(f\"Dynamic patch shape: ({config['window_days']}, {len(aligned_dynamic)}, {config['tile_size']}, {config['tile_size']})\")\n",
    "print(f\"\\nOutput directory: {config['out_root']}\")\n",
    "print(f\"Manifest file: {config['out_root']}/aligned_patches_manifest.csv\")\n",
    "\n",
    "if len(manifest) > 0:\n",
    "    print(f\"\\nüìù First few patches:\")\n",
    "    print(manifest.head(10))\n",
    "    \n",
    "    print(f\"\\nüìÖ Date range:\")\n",
    "    print(f\"  Earliest: {manifest['fire_date'].min()}\")\n",
    "    print(f\"  Latest: {manifest['fire_date'].max()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0120e82e-86b0-45df-93e4-af377e4e9a5d",
   "metadata": {},
   "source": [
    "# Combining both Positive and Negative .npy file creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0876e977-4bec-4522-b5f8-5d59fa4924f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Optional, Union, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "from rasterio.windows import bounds as window_bounds\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.mask import mask\n",
    "from tqdm import tqdm\n",
    "\n",
    "def create_reference_grid(\n",
    "    ca_boundary: str,\n",
    "    out_path: str,\n",
    "    dst_crs: str = \"EPSG:3310\",\n",
    "    dst_res: float = 100.0,\n",
    "    compress: str = \"lzw\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Create a reference grid that covers California at specified resolution.\n",
    "    This grid will be used to align ALL rasters (static and dynamic).\n",
    "    \n",
    "    Returns: path to the reference grid raster\n",
    "    \"\"\"\n",
    "    print(f\"[Creating Reference Grid]\")\n",
    "    ca = gpd.read_file(ca_boundary)\n",
    "    if ca.crs is None:\n",
    "        raise ValueError(\"CA boundary has no CRS\")\n",
    "    \n",
    "    ca = ca.to_crs(dst_crs)\n",
    "    bounds = ca.total_bounds  # minx, miny, maxx, maxy\n",
    "    \n",
    "    # Calculate dimensions\n",
    "    width = int(np.ceil((bounds[2] - bounds[0]) / dst_res))\n",
    "    height = int(np.ceil((bounds[3] - bounds[1]) / dst_res))\n",
    "    \n",
    "    # Create transform\n",
    "    from rasterio.transform import from_origin\n",
    "    transform = from_origin(bounds[0], bounds[3], dst_res, dst_res)\n",
    "    \n",
    "    # Create empty reference raster\n",
    "    profile = {\n",
    "        'driver': 'GTiff',\n",
    "        'height': height,\n",
    "        'width': width,\n",
    "        'count': 1,\n",
    "        'dtype': 'float32',\n",
    "        'crs': dst_crs,\n",
    "        'transform': transform,\n",
    "        'nodata': -9999.0,\n",
    "        'compress': compress\n",
    "    }\n",
    "    \n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "    with rasterio.open(out_path, 'w', **profile) as dst:\n",
    "        dst.write(np.zeros((height, width), dtype='float32'), 1)\n",
    "    \n",
    "    print(f\"  ‚úì Reference grid created: {width}x{height} px at {dst_res}m resolution\")\n",
    "    print(f\"  ‚úì Saved to: {out_path}\")\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def align_raster_to_reference(\n",
    "    src_raster: str,\n",
    "    reference_grid: str,\n",
    "    out_path: str,\n",
    "    ca_boundary: str,\n",
    "    compress: str = \"lzw\"\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Reproject and snap source raster to reference grid, then clip to CA boundary.\n",
    "    \"\"\"\n",
    "    print(f\"  Processing: {Path(src_raster).name}\")\n",
    "    \n",
    "    # Convert to Path object and create parent directories\n",
    "    out_path = Path(out_path)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Step 1: Reproject to match reference grid\n",
    "    with rasterio.open(reference_grid) as ref, rasterio.open(src_raster) as src:\n",
    "        profile = ref.profile.copy()\n",
    "        profile.update({'compress': compress})\n",
    "        \n",
    "        temp_path = str(out_path.parent / (out_path.name + \".temp.tif\"))\n",
    "        with rasterio.open(temp_path, 'w', **profile) as dst:\n",
    "            reproject(\n",
    "                source=rasterio.band(src, 1),\n",
    "                destination=rasterio.band(dst, 1),\n",
    "                src_transform=src.transform,\n",
    "                src_crs=src.crs,\n",
    "                dst_transform=ref.transform,\n",
    "                dst_crs=ref.crs,\n",
    "                resampling=Resampling.nearest,  # Use nearest for categorical data\n",
    "                src_nodata=src.nodata,\n",
    "                dst_nodata=ref.nodata\n",
    "            )\n",
    "    \n",
    "    # Step 2: Clip to CA boundary\n",
    "    ca = gpd.read_file(ca_boundary)\n",
    "    with rasterio.open(reference_grid) as ref:\n",
    "        if ca.crs != ref.crs:\n",
    "            ca = ca.to_crs(ref.crs)\n",
    "    \n",
    "    geoms = [geom.__geo_interface__ for geom in ca.geometry if geom is not None]\n",
    "    \n",
    "    with rasterio.open(temp_path) as src:\n",
    "        out_image, out_transform = mask(src, geoms, crop=True, nodata=src.nodata, filled=True)\n",
    "        out_meta = src.meta.copy()\n",
    "        out_meta.update({\n",
    "            \"height\": out_image.shape[1],\n",
    "            \"width\": out_image.shape[2],\n",
    "            \"transform\": out_transform,\n",
    "            \"compress\": compress\n",
    "        })\n",
    "        \n",
    "        with rasterio.open(str(out_path), \"w\", **out_meta) as dst:\n",
    "            dst.write(out_image)\n",
    "    \n",
    "    # Clean up temp file\n",
    "    if os.path.exists(temp_path):\n",
    "        os.remove(temp_path)\n",
    "    \n",
    "    print(f\"    ‚úì Aligned and clipped: {out_path.name}\")\n",
    "    return str(out_path)\n",
    "\n",
    "\n",
    "def discover_dynamic_rasters(\n",
    "    dynamic_folders: Dict[str, str],\n",
    "    pattern: str = \"*.tif\"\n",
    ") -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Discover all .tif files in each dynamic variable folder.\n",
    "    \n",
    "    Args:\n",
    "        dynamic_folders: {variable_name: folder_path containing all tifs for that variable}\n",
    "        pattern: file pattern to match (default: \"*.tif\")\n",
    "    \n",
    "    Returns:\n",
    "        {variable_name: [sorted list of paths]}\n",
    "    \"\"\"\n",
    "    dynamic_rasters = {}\n",
    "    for var_name, folder_path in dynamic_folders.items():\n",
    "        folder = Path(folder_path)\n",
    "        if not folder.exists():\n",
    "            raise ValueError(f\"Folder not found: {folder_path}\")\n",
    "        \n",
    "        tif_files = sorted(folder.glob(pattern))\n",
    "        if not tif_files:\n",
    "            raise ValueError(f\"No .tif files found in {folder_path}\")\n",
    "        \n",
    "        dynamic_rasters[var_name] = [str(p) for p in tif_files]\n",
    "        print(f\"  {var_name}: found {len(tif_files)} files\")\n",
    "    \n",
    "    return dynamic_rasters\n",
    "\n",
    "\n",
    "def align_all_rasters(\n",
    "    static_rasters: Dict[str, str],  # {variable_name: path}\n",
    "    dynamic_rasters: Dict[str, List[str]],  # {variable_name: [path1, path2, ...]}\n",
    "    landcover_raster: Optional[str],  # NEW: landcover path\n",
    "    reference_grid: str,\n",
    "    ca_boundary: str,\n",
    "    out_root: str,\n",
    "    compress: str = \"lzw\",\n",
    "    skip_existing: bool = True  # Skip if aligned file already exists\n",
    ") -> Tuple[Dict[str, str], Dict[str, List[str]], Optional[str]]:\n",
    "    \"\"\"\n",
    "    Align all static, dynamic, and landcover rasters to the reference grid.\n",
    "    \n",
    "    Args:\n",
    "        landcover_raster: Path to landcover.tif (optional)\n",
    "        skip_existing: If True, skip alignment if output file already exists\n",
    "    \n",
    "    Returns:\n",
    "        (aligned_static_paths, aligned_dynamic_paths, aligned_landcover_path)\n",
    "    \"\"\"\n",
    "    print(\"\\n[Aligning Static Rasters]\")\n",
    "    aligned_static = {}\n",
    "    for var_name, src_path in static_rasters.items():\n",
    "        out_path = os.path.join(out_root, \"aligned_static\", f\"{var_name}_aligned.tif\")\n",
    "        \n",
    "        if skip_existing and os.path.exists(out_path):\n",
    "            print(f\"  ‚úì Using existing: {Path(out_path).name}\")\n",
    "            aligned_static[var_name] = out_path\n",
    "        else:\n",
    "            aligned_static[var_name] = align_raster_to_reference(\n",
    "                src_path, reference_grid, out_path, ca_boundary, compress\n",
    "            )\n",
    "    \n",
    "    # NEW: Align landcover\n",
    "    aligned_landcover = None\n",
    "    if landcover_raster and os.path.exists(landcover_raster):\n",
    "        print(\"\\n[Aligning Landcover Raster]\")\n",
    "        out_path = os.path.join(out_root, \"aligned_static\", \"landcover_aligned.tif\")\n",
    "        \n",
    "        if skip_existing and os.path.exists(out_path):\n",
    "            print(f\"  ‚úì Using existing: {Path(out_path).name}\")\n",
    "            aligned_landcover = out_path\n",
    "        else:\n",
    "            aligned_landcover = align_raster_to_reference(\n",
    "                landcover_raster, reference_grid, out_path, ca_boundary, compress\n",
    "            )\n",
    "    \n",
    "    print(\"\\n[Aligning Dynamic Rasters]\")\n",
    "    aligned_dynamic = {}\n",
    "    for var_name, src_paths in dynamic_rasters.items():\n",
    "        print(f\"\\n  Processing {var_name}: {len(src_paths)} files\")\n",
    "        aligned_dynamic[var_name] = []\n",
    "        \n",
    "        for src_path in tqdm(src_paths, desc=f\"  Aligning {var_name}\"):\n",
    "            # Extract date from filename\n",
    "            date_match = re.search(r'(\\d{8})', Path(src_path).stem)\n",
    "            date_str = date_match.group(1) if date_match else f\"t{len(aligned_dynamic[var_name]):06d}\"\n",
    "            \n",
    "            out_path = os.path.join(\n",
    "                out_root, \"aligned_dynamic\", var_name, f\"{var_name}_{date_str}_aligned.tif\"\n",
    "            )\n",
    "            \n",
    "            if skip_existing and os.path.exists(out_path):\n",
    "                aligned_dynamic[var_name].append(out_path)\n",
    "            else:\n",
    "                aligned_dynamic[var_name].append(\n",
    "                    align_raster_to_reference(src_path, reference_grid, out_path, ca_boundary, compress)\n",
    "                )\n",
    "    \n",
    "    return aligned_static, aligned_dynamic, aligned_landcover\n",
    "\n",
    "\n",
    "DATE8_RE = re.compile(r\"(?<!\\d)(\\d{8})(?!\\d)\")\n",
    "\n",
    "def parse_date_from_path(raster_path: str) -> Optional[datetime]:\n",
    "    \"\"\"Extract date from filename (YYYYMMDD format)\"\"\"\n",
    "    m = DATE8_RE.search(Path(raster_path).stem)\n",
    "    if m:\n",
    "        try:\n",
    "            return datetime.strptime(m.group(1), \"%Y%m%d\")\n",
    "        except:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "\n",
    "def one_hot_encode_landcover(landcover_patch: np.ndarray, num_classes: int = 10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert landcover patch to one-hot encoded format.\n",
    "    \n",
    "    Args:\n",
    "        landcover_patch: 2D array with landcover classes (1-10)\n",
    "        num_classes: Number of landcover classes (default: 10)\n",
    "    \n",
    "    Returns:\n",
    "        3D array of shape (num_classes, height, width) with binary values\n",
    "    \"\"\"\n",
    "    height, width = landcover_patch.shape\n",
    "    one_hot = np.zeros((num_classes, height, width), dtype=np.float32)\n",
    "    \n",
    "    valid_mask = ~np.isnan(landcover_patch)\n",
    "    \n",
    "    for class_id in range(1, num_classes + 1):\n",
    "        class_mask = (landcover_patch == class_id) & valid_mask\n",
    "        one_hot[class_id - 1] = class_mask.astype(np.float32)\n",
    "    \n",
    "    return one_hot\n",
    "\n",
    "\n",
    "def build_aligned_fire_dataset(\n",
    "    aligned_static: Dict[str, str],  \n",
    "    aligned_dynamic: Dict[str, List[str]], \n",
    "    aligned_landcover: Optional[str],  \n",
    "    fire_dataset: str,\n",
    "    fire_date_field: str,\n",
    "    ca_boundary: str,\n",
    "    out_root: str = \"output_aligned_fire_patches\",\n",
    "    tile_size: int = 25,\n",
    "    window_days: int = 10,\n",
    "    min_pos_frac: float = 0.80,\n",
    "    min_valid_frac: float = 0.50,\n",
    "    require_all_valid: bool = True,\n",
    "    strict_inside: bool = True,\n",
    "    num_landcover_classes: int = 10,  # NEW: number of landcover classes\n",
    "    # Controls for individual TIFs\n",
    "    write_individual_static_tifs: bool = True,\n",
    "    write_individual_dynamic_tifs_days: int = 2,\n",
    "    write_individual_landcover_tifs: bool = True,  # NEW\n",
    "    tif_compress: str = \"lzw\",\n",
    "    tif_nodata: float = -9999.0,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create aligned .npy patches for static, dynamic, and landcover data.\n",
    "    \n",
    "    NEW: Landcover is one-hot encoded to shape (num_classes, tile_size, tile_size)\n",
    "    \n",
    "    Output files:\n",
    "      ‚Ä¢ Static NPY:     YYYYMMDD_row_col_static.npy\n",
    "      ‚Ä¢ Dynamic NPY:    YYYYMMDD_row_col_dynamic.npy\n",
    "      ‚Ä¢ Landcover NPY:  YYYYMMDD_row_col_clc_vec.npy  (one-hot encoded)\n",
    "    \"\"\"\n",
    "    from rasterio.windows import transform as window_transform\n",
    "\n",
    "    out_root = Path(out_root)\n",
    "    out_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Reference from first static raster\n",
    "    ref_path = next(iter(aligned_static.values()))\n",
    "    with rasterio.open(ref_path) as ref:\n",
    "        ref_crs = ref.crs\n",
    "        ref_transform = ref.transform\n",
    "        ref_height = ref.height\n",
    "        ref_width = ref.width\n",
    "\n",
    "    print(f\"\\n[Reference Grid] {ref_width}x{ref_height} px\")\n",
    "\n",
    "    # Boundary\n",
    "    ca = gpd.read_file(ca_boundary)\n",
    "    if ca.crs != ref_crs:\n",
    "        ca = ca.to_crs(ref_crs)\n",
    "    ca_union = ca.unary_union\n",
    "\n",
    "    # Fires\n",
    "    print(\"\\n[Loading Fire Dataset]\")\n",
    "    fires = gpd.read_file(fire_dataset)\n",
    "    if fires.crs != ref_crs:\n",
    "        fires = fires.to_crs(ref_crs)\n",
    "    if fire_date_field not in fires.columns:\n",
    "        raise ValueError(f\"Fire date field '{fire_date_field}' not found\")\n",
    "\n",
    "    def _pfd(v):\n",
    "        if pd.isna(v): return None\n",
    "        try: return pd.to_datetime(str(v)).date()\n",
    "        except: return None\n",
    "\n",
    "    fires['__fire_date__'] = fires[fire_date_field].apply(_pfd)\n",
    "    fires = fires.dropna(subset=['__fire_date__'])\n",
    "    fires_by_date = {d: grp for d, grp in fires.groupby('__fire_date__')}\n",
    "    print(f\"  ‚úì Found {len(fires)} fire polygons across {len(fires_by_date)} unique dates\")\n",
    "\n",
    "    # Dynamic index\n",
    "    print(\"\\n[Indexing Dynamic Rasters]\")\n",
    "    dynamic_index = {}\n",
    "    for var_name, paths in aligned_dynamic.items():\n",
    "        dynamic_index[var_name] = {}\n",
    "        for p in paths:\n",
    "            dt = parse_date_from_path(p)\n",
    "            if dt:\n",
    "                dynamic_index[var_name][dt.date()] = p\n",
    "        print(f\"  {var_name}: {len(dynamic_index[var_name])} dates\")\n",
    "\n",
    "    # Date intersection across dynamic vars\n",
    "    all_dates = set.intersection(*[set(d.keys()) for d in dynamic_index.values()])\n",
    "    all_dates = sorted(all_dates)\n",
    "    print(f\"  ‚úì {len(all_dates)} dates available across all dynamic variables\")\n",
    "\n",
    "    # Output dirs\n",
    "    # static_dir = out_root / \"static_patches\"\n",
    "    # dynamic_dir = out_root / \"dynamic_patches\"\n",
    "    # landcover_dir = out_root / \"landcover_patches\"  # NEW\n",
    "    # static_dir.mkdir(exist_ok=True)\n",
    "    # dynamic_dir.mkdir(exist_ok=True)\n",
    "    # landcover_dir.mkdir(exist_ok=True)\n",
    "    npy_dir = Path(out_root) / \"positive\"\n",
    "    npy_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Individual per-variable GeoTIFF dirs\n",
    "    static_tif_root = out_root / \"static_tifs\"\n",
    "    dynamic_tif_root = out_root / \"dynamic_tifs\"\n",
    "    landcover_tif_root = out_root / \"landcover_tifs\"  # NEW\n",
    "    \n",
    "    if write_individual_static_tifs:\n",
    "        static_tif_root.mkdir(exist_ok=True)\n",
    "    if write_individual_dynamic_tifs_days and write_individual_dynamic_tifs_days > 0:\n",
    "        dynamic_tif_root.mkdir(exist_ok=True)\n",
    "    if write_individual_landcover_tifs and aligned_landcover:\n",
    "        landcover_tif_root.mkdir(exist_ok=True)\n",
    "\n",
    "    manifest_rows = []\n",
    "    patch_id = 0\n",
    "\n",
    "    static_vars = sorted(aligned_static.keys())\n",
    "    dynamic_vars = sorted(aligned_dynamic.keys())\n",
    "\n",
    "    print(f\"\\n[Extracting Patches]\")\n",
    "    print(f\"  Static variables: {static_vars}\")\n",
    "    print(f\"  Dynamic variables: {dynamic_vars}\")\n",
    "    print(f\"  Landcover classes: {num_landcover_classes if aligned_landcover else 'N/A'}\")\n",
    "    print(f\"  Window days: {window_days}\")\n",
    "\n",
    "    for T in tqdm(all_dates, desc=\"Processing dates\"):\n",
    "        fires_T = fires_by_date.get(T)\n",
    "        if fires_T is None or fires_T.empty:\n",
    "            continue\n",
    "\n",
    "        sindex = fires_T.sindex\n",
    "\n",
    "        needed_dates = [T - timedelta(days=i) for i in range(window_days)]\n",
    "        if not all(d in all_dates for d in needed_dates):\n",
    "            continue\n",
    "\n",
    "        rows = range(0, ref_height - (ref_height % tile_size), tile_size)\n",
    "        cols = range(0, ref_width - (ref_width % tile_size), tile_size)\n",
    "\n",
    "        for r0 in rows:\n",
    "            for c0 in cols:\n",
    "                win = Window(col_off=c0, row_off=r0, width=tile_size, height=tile_size)\n",
    "                left, bottom, right, top = window_bounds(win, transform=ref_transform)\n",
    "                tile_poly = box(left, bottom, right, top)\n",
    "\n",
    "                if strict_inside and not ca_union.covers(tile_poly):\n",
    "                    continue\n",
    "\n",
    "                cand_idx = list(sindex.intersection(tile_poly.bounds))\n",
    "                if not cand_idx:\n",
    "                    continue\n",
    "\n",
    "                inter_area = 0.0\n",
    "                for geom in fires_T.geometry.iloc[cand_idx]:\n",
    "                    if geom is None or geom.is_empty:\n",
    "                        continue\n",
    "                    try:\n",
    "                        inter_area += geom.intersection(tile_poly).area\n",
    "                    except Exception:\n",
    "                        inter_area += geom.buffer(0).intersection(tile_poly).area\n",
    "\n",
    "                tile_area = tile_poly.area\n",
    "                overlap_frac = inter_area / tile_area if tile_area > 0 else 0.0\n",
    "                if overlap_frac < min_pos_frac:\n",
    "                    continue\n",
    "\n",
    "                # --- Static stack ---\n",
    "                static_stack = []\n",
    "                valid_static = True\n",
    "                for var_name in static_vars:\n",
    "                    with rasterio.open(aligned_static[var_name]) as src:\n",
    "                        patch = src.read(1, window=win, masked=True)\n",
    "                        if patch.shape != (tile_size, tile_size):\n",
    "                            valid_static = False; break\n",
    "                        invalid = patch.mask\n",
    "                        if require_all_valid and invalid.any():\n",
    "                            valid_static = False; break\n",
    "                        elif not require_all_valid:\n",
    "                            valid_frac = 1.0 - float(invalid.mean())\n",
    "                            if valid_frac < min_valid_frac:\n",
    "                                valid_static = False; break\n",
    "                        arr = np.asarray(patch, dtype=np.float32)\n",
    "                        if invalid.any():\n",
    "                            arr = np.where(invalid, np.nan, arr)\n",
    "                        static_stack.append(arr)\n",
    "                if not valid_static:\n",
    "                    continue\n",
    "\n",
    "                # --- Landcover (one-hot encoded) ---\n",
    "                landcover_array = None\n",
    "                if aligned_landcover:\n",
    "                    with rasterio.open(aligned_landcover) as src:\n",
    "                        lc_patch = src.read(1, window=win, masked=True)\n",
    "                        if lc_patch.shape != (tile_size, tile_size):\n",
    "                            continue\n",
    "                        \n",
    "                        # Convert to float and handle nodata\n",
    "                        lc_arr = np.asarray(lc_patch, dtype=np.float32)\n",
    "                        if lc_patch.mask.any():\n",
    "                            lc_arr = np.where(lc_patch.mask, np.nan, lc_arr)\n",
    "                        \n",
    "                        # One-hot encode\n",
    "                        landcover_array = one_hot_encode_landcover(lc_arr, num_landcover_classes)\n",
    "\n",
    "                # --- Dynamic stack ---\n",
    "                dynamic_stack = []\n",
    "                valid_dynamic = True\n",
    "                for date_offset in range(window_days):\n",
    "                    target_date = T - timedelta(days=date_offset)\n",
    "                    day_stack = []\n",
    "                    for var_name in dynamic_vars:\n",
    "                        raster_path = dynamic_index[var_name][target_date]\n",
    "                        with rasterio.open(raster_path) as src:\n",
    "                            patch = src.read(1, window=win, masked=True)\n",
    "                            if patch.shape != (tile_size, tile_size):\n",
    "                                valid_dynamic = False; break\n",
    "                            invalid = patch.mask\n",
    "                            if require_all_valid and invalid.any():\n",
    "                                valid_dynamic = False; break\n",
    "                            elif not require_all_valid:\n",
    "                                valid_frac = 1.0 - float(invalid.mean())\n",
    "                                if valid_frac < min_valid_frac:\n",
    "                                    valid_dynamic = False; break\n",
    "                            arr = np.asarray(patch, dtype=np.float32)\n",
    "                            if invalid.any():\n",
    "                                arr = np.where(invalid, np.nan, arr)\n",
    "                            day_stack.append(arr)\n",
    "                    if not valid_dynamic:\n",
    "                        break\n",
    "                    dynamic_stack.append(np.stack(day_stack, axis=0))\n",
    "                if not valid_dynamic:\n",
    "                    continue\n",
    "\n",
    "                # --- Save NPYs ---\n",
    "                patch_id += 1\n",
    "                fire_day_str = T.strftime(\"%Y%m%d\")\n",
    "                static_array = np.stack(static_stack, axis=0)\n",
    "                dynamic_array = np.stack(dynamic_stack, axis=0)\n",
    "\n",
    "                static_path = npy_dir / f\"{fire_day_str}_{int(r0)}_{int(c0)}_static.npy\"\n",
    "                dynamic_path = npy_dir / f\"{fire_day_str}_{int(r0)}_{int(c0)}_dynamic.npy\"\n",
    "                np.save(static_path, static_array.astype(np.float32))\n",
    "                np.save(dynamic_path, dynamic_array.astype(np.float32))\n",
    "                \n",
    "                # NEW: Save landcover as clc_vec.npy\n",
    "                landcover_path = None\n",
    "                if landcover_array is not None:\n",
    "                    landcover_path = npy_dir / f\"{fire_day_str}_{int(r0)}_{int(c0)}_clc_vec.npy\"\n",
    "                    np.save(landcover_path, landcover_array.astype(np.float32))\n",
    "\n",
    "                # --- Write individual GeoTIFFs ---\n",
    "                tile_transform = window_transform(win, ref_transform)\n",
    "\n",
    "                # 1) Static TIFs\n",
    "                if write_individual_static_tifs:\n",
    "                    for idx, var_name in enumerate(static_vars):\n",
    "                        arr = static_array[idx]\n",
    "                        var_dir = (static_tif_root / var_name)\n",
    "                        var_dir.mkdir(parents=True, exist_ok=True)\n",
    "                        out_tif = var_dir / f\"{fire_day_str}_{int(r0)}_{int(c0)}_static.tif\"\n",
    "                        profile = {\n",
    "                            \"driver\": \"GTiff\",\n",
    "                            \"height\": tile_size,\n",
    "                            \"width\": tile_size,\n",
    "                            \"count\": 1,\n",
    "                            \"dtype\": \"float32\",\n",
    "                            \"crs\": ref_crs,\n",
    "                            \"transform\": tile_transform,\n",
    "                            \"nodata\": tif_nodata,\n",
    "                            \"compress\": tif_compress,\n",
    "                        }\n",
    "                        with rasterio.open(out_tif, \"w\", **profile) as dst:\n",
    "                            dst.write(np.where(np.isnan(arr), tif_nodata, arr).astype(np.float32), 1)\n",
    "                            dst.update_tags(\n",
    "                                patch_id=int(patch_id),\n",
    "                                fire_date=str(T),\n",
    "                                row_off=int(r0),\n",
    "                                col_off=int(c0),\n",
    "                                var_name=var_name,\n",
    "                            )\n",
    "\n",
    "                # 2) Dynamic TIFs (first K days)\n",
    "                K = max(0, min(int(write_individual_dynamic_tifs_days), window_days))\n",
    "                for d in range(K):\n",
    "                    day_date = (T - timedelta(days=d)).strftime(\"%Y%m%d\")\n",
    "                    for vidx, var_name in enumerate(dynamic_vars):\n",
    "                        arr = dynamic_array[d, vidx]\n",
    "                        var_dir = (dynamic_tif_root / var_name)\n",
    "                        var_dir.mkdir(parents=True, exist_ok=True)\n",
    "                        out_tif = var_dir / f\"{day_date}_{int(r0)}_{int(c0)}_dynamic.tif\"\n",
    "                        profile = {\n",
    "                            \"driver\": \"GTiff\",\n",
    "                            \"height\": tile_size,\n",
    "                            \"width\": tile_size,\n",
    "                            \"count\": 1,\n",
    "                            \"dtype\": \"float32\",\n",
    "                            \"crs\": ref_crs,\n",
    "                            \"transform\": tile_transform,\n",
    "                            \"nodata\": tif_nodata,\n",
    "                            \"compress\": tif_compress,\n",
    "                        }\n",
    "                        with rasterio.open(out_tif, \"w\", **profile) as dst:\n",
    "                            dst.write(np.where(np.isnan(arr), tif_nodata, arr).astype(np.float32), 1)\n",
    "                            dst.update_tags(\n",
    "                                patch_id=int(patch_id),\n",
    "                                fire_date=str(T),\n",
    "                                day_index=int(d),\n",
    "                                day_date=day_date,\n",
    "                                row_off=int(r0),\n",
    "                                col_off=int(c0),\n",
    "                                var_name=var_name,\n",
    "                            )\n",
    "\n",
    "                # 3) NEW: Landcover TIFs (one per class)\n",
    "                if write_individual_landcover_tifs and landcover_array is not None:\n",
    "                    for class_id in range(num_landcover_classes):\n",
    "                        arr = landcover_array[class_id]\n",
    "                        class_name = f\"class_{class_id + 1}\"\n",
    "                        var_dir = (landcover_tif_root / class_name)\n",
    "                        var_dir.mkdir(parents=True, exist_ok=True)\n",
    "                        out_tif = var_dir / f\"{fire_day_str}_{int(r0)}_{int(c0)}_clc_vec.tif\"\n",
    "                        profile = {\n",
    "                            \"driver\": \"GTiff\",\n",
    "                            \"height\": tile_size,\n",
    "                            \"width\": tile_size,\n",
    "                            \"count\": 1,\n",
    "                            \"dtype\": \"float32\",\n",
    "                            \"crs\": ref_crs,\n",
    "                            \"transform\": tile_transform,\n",
    "                            \"nodata\": tif_nodata,\n",
    "                            \"compress\": tif_compress,\n",
    "                        }\n",
    "                        with rasterio.open(out_tif, \"w\", **profile) as dst:\n",
    "                            dst.write(arr.astype(np.float32), 1)\n",
    "                            dst.update_tags(\n",
    "                                patch_id=int(patch_id),\n",
    "                                fire_date=str(T),\n",
    "                                row_off=int(r0),\n",
    "                                col_off=int(c0),\n",
    "                                landcover_class=int(class_id + 1),\n",
    "                            )\n",
    "\n",
    "                # Manifest\n",
    "                manifest_row = {\n",
    "                    'patch_id': patch_id,\n",
    "                    'static_path': str(static_path),\n",
    "                    'dynamic_path': str(dynamic_path),\n",
    "                    'fire_date': T.strftime('%Y-%m-%d'),\n",
    "                    'row_off': r0,\n",
    "                    'col_off': c0,\n",
    "                    'left': left,\n",
    "                    'bottom': bottom,\n",
    "                    'right': right,\n",
    "                    'top': top,\n",
    "                    'overlap_frac': overlap_frac,\n",
    "                    'static_vars': ','.join(static_vars),\n",
    "                    'dynamic_vars': ','.join(dynamic_vars),\n",
    "                    'window_days': window_days,\n",
    "                }\n",
    "                if landcover_path:\n",
    "                    manifest_row['landcover_path'] = str(landcover_path)\n",
    "                    manifest_row['landcover_classes'] = num_landcover_classes\n",
    "                \n",
    "                manifest_rows.append(manifest_row)\n",
    "\n",
    "    # Save manifest\n",
    "    manifest = pd.DataFrame(manifest_rows)\n",
    "    manifest_path = out_root / \"aligned_patches_manifest.csv\"\n",
    "    manifest.to_csv(manifest_path, index=False)\n",
    "\n",
    "    print(f\"\\n‚úÖ Complete!\")\n",
    "    print(f\"  Total patches: {len(manifest)}\")\n",
    "    print(f\"  Static shape: ({len(static_vars)}, {tile_size}, {tile_size})\")\n",
    "    print(f\"  Dynamic shape: ({window_days}, {len(dynamic_vars)}, {tile_size}, {tile_size})\")\n",
    "    if aligned_landcover:\n",
    "        print(f\"  Landcover shape: ({num_landcover_classes}, {tile_size}, {tile_size}) [one-hot encoded]\")\n",
    "    print(f\"  Manifest: {manifest_path}\")\n",
    "    print(f\"  Static TIFs: {static_tif_root if write_individual_static_tifs else 'disabled'}\")\n",
    "    print(f\"  Dynamic TIFs (first {write_individual_dynamic_tifs_days} days): \"\n",
    "          f\"{dynamic_tif_root if write_individual_dynamic_tifs_days>0 else 'disabled'}\")\n",
    "    if aligned_landcover:\n",
    "        print(f\"  Landcover TIFs: {landcover_tif_root if write_individual_landcover_tifs else 'disabled'}\")\n",
    "\n",
    "    return manifest\n",
    "\n",
    "\n",
    "def build_negative_fire_dataset(\n",
    "    aligned_static: Dict[str, str],\n",
    "    aligned_dynamic: Dict[str, List[str]],\n",
    "    aligned_landcover: Optional[str],\n",
    "    fire_dataset: str,\n",
    "    fire_date_field: str,\n",
    "    ca_boundary: str,\n",
    "    out_root: str = \"output_aligned_fire_patches\",\n",
    "    tile_size: int = 25,\n",
    "    window_days: int = 10,\n",
    "    samples_per_year: int = 1000,\n",
    "    min_valid_frac: float = 0.50,\n",
    "    require_all_valid: bool = True,\n",
    "    num_landcover_classes: int = 10,\n",
    "    start_year: int = 2015,\n",
    "    end_year: int = 2024,\n",
    "    max_attempts_per_year: int = 50000,\n",
    "    tif_nodata: float = -9999.0,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create negative samples where NO fire occurred in the 10-day window at sampled locations.\n",
    "    \n",
    "    Args:\n",
    "        samples_per_year: Number of negative samples to generate per year (default: 3000)\n",
    "        start_year: First year to sample from (default: 2015)\n",
    "        end_year: Last year to sample from (default: 2024)\n",
    "        max_attempts_per_year: Maximum random sampling attempts per year before giving up\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with manifest of negative samples\n",
    "    \"\"\"\n",
    "    from rasterio.windows import transform as window_transform\n",
    "    import random\n",
    "\n",
    "    out_root = Path(out_root)\n",
    "    \n",
    "    # Reference from first static raster\n",
    "    ref_path = next(iter(aligned_static.values()))\n",
    "    with rasterio.open(ref_path) as ref:\n",
    "        ref_crs = ref.crs\n",
    "        ref_transform = ref.transform\n",
    "        ref_height = ref.height\n",
    "        ref_width = ref.width\n",
    "\n",
    "    print(f\"\\n[Reference Grid] {ref_width}x{ref_height} px\")\n",
    "\n",
    "    # Boundary\n",
    "    ca = gpd.read_file(ca_boundary)\n",
    "    if ca.crs != ref_crs:\n",
    "        ca = ca.to_crs(ref_crs)\n",
    "    ca_union = ca.unary_union\n",
    "\n",
    "    # Fires\n",
    "    print(\"\\n[Loading Fire Dataset]\")\n",
    "    fires = gpd.read_file(fire_dataset)\n",
    "    if fires.crs != ref_crs:\n",
    "        fires = fires.to_crs(ref_crs)\n",
    "    if fire_date_field not in fires.columns:\n",
    "        raise ValueError(f\"Fire date field '{fire_date_field}' not found\")\n",
    "\n",
    "    def _pfd(v):\n",
    "        if pd.isna(v): return None\n",
    "        try: return pd.to_datetime(str(v)).date()\n",
    "        except: return None\n",
    "\n",
    "    fires['__fire_date__'] = fires[fire_date_field].apply(_pfd)\n",
    "    fires = fires.dropna(subset=['__fire_date__'])\n",
    "    fires_by_date = {d: grp for d, grp in fires.groupby('__fire_date__')}\n",
    "    print(f\"  ‚úì Found {len(fires)} fire polygons across {len(fires_by_date)} unique dates\")\n",
    "\n",
    "    # Dynamic index\n",
    "    print(\"\\n[Indexing Dynamic Rasters]\")\n",
    "    dynamic_index = {}\n",
    "    for var_name, paths in aligned_dynamic.items():\n",
    "        dynamic_index[var_name] = {}\n",
    "        for p in paths:\n",
    "            dt = parse_date_from_path(p)\n",
    "            if dt:\n",
    "                dynamic_index[var_name][dt.date()] = p\n",
    "        print(f\"  {var_name}: {len(dynamic_index[var_name])} dates\")\n",
    "\n",
    "    # Date intersection across dynamic vars\n",
    "    all_dates = set.intersection(*[set(d.keys()) for d in dynamic_index.values()])\n",
    "    all_dates = sorted(all_dates)\n",
    "    print(f\"  ‚úì {len(all_dates)} dates available across all dynamic variables\")\n",
    "\n",
    "    negative_root = out_root / \"negative\"\n",
    "    negative_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    manifest_rows = []\n",
    "    patch_id = 0\n",
    "\n",
    "    static_vars = sorted(aligned_static.keys())\n",
    "    dynamic_vars = sorted(aligned_dynamic.keys())\n",
    "\n",
    "    print(f\"\\n[Extracting NEGATIVE Patches]\")\n",
    "    print(f\"  Static variables: {static_vars}\")\n",
    "    print(f\"  Dynamic variables: {dynamic_vars}\")\n",
    "    print(f\"  Landcover classes: {num_landcover_classes if aligned_landcover else 'N/A'}\")\n",
    "    print(f\"  Window days: {window_days}\")\n",
    "    print(f\"  Samples per year: {samples_per_year}\")\n",
    "    print(f\"  Year range: {start_year}-{end_year}\")\n",
    "\n",
    "    # Pre-compute valid tile positions (inside CA boundary)\n",
    "    print(\"\\n[Pre-computing valid tile positions]\")\n",
    "    max_row = ref_height - tile_size\n",
    "    max_col = ref_width - tile_size\n",
    "    \n",
    "    # Generate all possible tile positions\n",
    "    all_tile_positions = []\n",
    "    for r0 in range(0, max_row, tile_size):\n",
    "        for c0 in range(0, max_col, tile_size):\n",
    "            win = Window(col_off=c0, row_off=r0, width=tile_size, height=tile_size)\n",
    "            left, bottom, right, top = window_bounds(win, transform=ref_transform)\n",
    "            tile_poly = box(left, bottom, right, top)\n",
    "            \n",
    "            # Only keep tiles that are inside CA\n",
    "            if ca_union.covers(tile_poly):\n",
    "                all_tile_positions.append((r0, c0, tile_poly, left, bottom, right, top))\n",
    "    \n",
    "    print(f\"  ‚úì Found {len(all_tile_positions)} valid tile positions inside California\")\n",
    "\n",
    "    # Process each year\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        print(f\"\\n[Processing Year {year}]\")\n",
    "        \n",
    "        # Get dates for this year\n",
    "        year_dates = [d for d in all_dates if d.year == year]\n",
    "        \n",
    "        # Filter dates that have 10-day window available\n",
    "        valid_dates = []\n",
    "        for T in year_dates:\n",
    "            needed_dates = [T - timedelta(days=i) for i in range(window_days)]\n",
    "            if all(d in all_dates for d in needed_dates):\n",
    "                valid_dates.append(T)\n",
    "        \n",
    "        print(f\"  Valid dates with 10-day window: {len(valid_dates)}\")\n",
    "        \n",
    "        if len(valid_dates) == 0:\n",
    "            print(f\"  ‚ö†Ô∏è  No valid dates found for year {year}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        year_samples = 0\n",
    "        attempts = 0\n",
    "        \n",
    "        with tqdm(total=samples_per_year, desc=f\"  Sampling year {year}\") as pbar:\n",
    "            while year_samples < samples_per_year and attempts < max_attempts_per_year:\n",
    "                attempts += 1\n",
    "                \n",
    "                # Randomly select a date\n",
    "                T = random.choice(valid_dates)\n",
    "                \n",
    "                # Get 10-day window\n",
    "                needed_dates = [T - timedelta(days=i) for i in range(window_days)]\n",
    "                \n",
    "                # Check if any fire occurred in this 10-day window\n",
    "                fires_in_window = []\n",
    "                has_fire_in_window = False\n",
    "                for date in needed_dates:\n",
    "                    if date in fires_by_date:\n",
    "                        fires_in_window.extend(fires_by_date[date].geometry.tolist())\n",
    "                        has_fire_in_window = True\n",
    "                \n",
    "                # Create spatial index for fires in this window (if any)\n",
    "                if has_fire_in_window:\n",
    "                    fire_union = gpd.GeoSeries(fires_in_window, crs=ref_crs).union_all()\n",
    "                else:\n",
    "                    fire_union = None\n",
    "                \n",
    "                # Randomly select a tile position\n",
    "                r0, c0, tile_poly, left, bottom, right, top = random.choice(all_tile_positions)\n",
    "                \n",
    "                # Check if this tile intersects with any fire in the 10-day window\n",
    "                if fire_union is not None:\n",
    "                    try:\n",
    "                        if tile_poly.intersects(fire_union):\n",
    "                            continue  # Skip this tile, has fire\n",
    "                    except Exception:\n",
    "                        # Handle geometry errors\n",
    "                        if tile_poly.intersects(fire_union.buffer(0)):\n",
    "                            continue\n",
    "                \n",
    "                # This tile has NO fire in the 10-day window, extract data\n",
    "                win = Window(col_off=c0, row_off=r0, width=tile_size, height=tile_size)\n",
    "                \n",
    "                # --- Static stack ---\n",
    "                static_stack = []\n",
    "                valid_static = True\n",
    "                for var_name in static_vars:\n",
    "                    with rasterio.open(aligned_static[var_name]) as src:\n",
    "                        patch = src.read(1, window=win, masked=True)\n",
    "                        if patch.shape != (tile_size, tile_size):\n",
    "                            valid_static = False\n",
    "                            break\n",
    "                        invalid = patch.mask\n",
    "                        if require_all_valid and invalid.any():\n",
    "                            valid_static = False\n",
    "                            break\n",
    "                        elif not require_all_valid:\n",
    "                            valid_frac = 1.0 - float(invalid.mean())\n",
    "                            if valid_frac < min_valid_frac:\n",
    "                                valid_static = False\n",
    "                                break\n",
    "                        arr = np.asarray(patch, dtype=np.float32)\n",
    "                        if invalid.any():\n",
    "                            arr = np.where(invalid, np.nan, arr)\n",
    "                        static_stack.append(arr)\n",
    "                if not valid_static:\n",
    "                    continue\n",
    "\n",
    "                # --- Landcover (one-hot encoded) ---\n",
    "                landcover_array = None\n",
    "                if aligned_landcover:\n",
    "                    with rasterio.open(aligned_landcover) as src:\n",
    "                        lc_patch = src.read(1, window=win, masked=True)\n",
    "                        if lc_patch.shape != (tile_size, tile_size):\n",
    "                            continue\n",
    "                        \n",
    "                        lc_arr = np.asarray(lc_patch, dtype=np.float32)\n",
    "                        if lc_patch.mask.any():\n",
    "                            lc_arr = np.where(lc_patch.mask, np.nan, lc_arr)\n",
    "                        \n",
    "                        landcover_array = one_hot_encode_landcover(lc_arr, num_landcover_classes)\n",
    "\n",
    "                # --- Dynamic stack ---\n",
    "                dynamic_stack = []\n",
    "                valid_dynamic = True\n",
    "                for date_offset in range(window_days):\n",
    "                    target_date = T - timedelta(days=date_offset)\n",
    "                    day_stack = []\n",
    "                    for var_name in dynamic_vars:\n",
    "                        raster_path = dynamic_index[var_name][target_date]\n",
    "                        with rasterio.open(raster_path) as src:\n",
    "                            patch = src.read(1, window=win, masked=True)\n",
    "                            if patch.shape != (tile_size, tile_size):\n",
    "                                valid_dynamic = False\n",
    "                                break\n",
    "                            invalid = patch.mask\n",
    "                            if require_all_valid and invalid.any():\n",
    "                                valid_dynamic = False\n",
    "                                break\n",
    "                            elif not require_all_valid:\n",
    "                                valid_frac = 1.0 - float(invalid.mean())\n",
    "                                if valid_frac < min_valid_frac:\n",
    "                                    valid_dynamic = False\n",
    "                                    break\n",
    "                            arr = np.asarray(patch, dtype=np.float32)\n",
    "                            if invalid.any():\n",
    "                                arr = np.where(invalid, np.nan, arr)\n",
    "                            day_stack.append(arr)\n",
    "                    if not valid_dynamic:\n",
    "                        break\n",
    "                    dynamic_stack.append(np.stack(day_stack, axis=0))\n",
    "                if not valid_dynamic:\n",
    "                    continue\n",
    "\n",
    "                # --- Save NPYs ---\n",
    "                patch_id += 1\n",
    "                year_samples += 1\n",
    "                pbar.update(1)\n",
    "                \n",
    "                fire_day_str = T.strftime(\"%Y%m%d\")\n",
    "                static_array = np.stack(static_stack, axis=0)\n",
    "                dynamic_array = np.stack(dynamic_stack, axis=0)\n",
    "\n",
    "                static_path = negative_root / f\"{fire_day_str}_{int(r0)}_{int(c0)}_static.npy\"\n",
    "                dynamic_path = negative_root / f\"{fire_day_str}_{int(r0)}_{int(c0)}_dynamic.npy\"\n",
    "                np.save(static_path, static_array.astype(np.float32))\n",
    "                np.save(dynamic_path, dynamic_array.astype(np.float32))\n",
    "                \n",
    "                landcover_path = None\n",
    "                if landcover_array is not None:\n",
    "                    landcover_path = negative_root / f\"{fire_day_str}_{int(r0)}_{int(c0)}_clc_vec.npy\"\n",
    "                    np.save(landcover_path, landcover_array.astype(np.float32))\n",
    "\n",
    "                # Manifest\n",
    "                manifest_row = {\n",
    "                    'patch_id': patch_id,\n",
    "                    'static_path': str(static_path),\n",
    "                    'dynamic_path': str(dynamic_path),\n",
    "                    'sample_date': T.strftime('%Y-%m-%d'),\n",
    "                    'year': year,\n",
    "                    'row_off': r0,\n",
    "                    'col_off': c0,\n",
    "                    'left': left,\n",
    "                    'bottom': bottom,\n",
    "                    'right': right,\n",
    "                    'top': top,\n",
    "                    'label': 0,  # Negative sample\n",
    "                    'static_vars': ','.join(static_vars),\n",
    "                    'dynamic_vars': ','.join(dynamic_vars),\n",
    "                    'window_days': window_days,\n",
    "                }\n",
    "                if landcover_path:\n",
    "                    manifest_row['landcover_path'] = str(landcover_path)\n",
    "                    manifest_row['landcover_classes'] = num_landcover_classes\n",
    "                \n",
    "                manifest_rows.append(manifest_row)\n",
    "        \n",
    "        print(f\"  ‚úì Year {year}: Generated {year_samples} negative samples (attempts: {attempts})\")\n",
    "\n",
    "    # Save manifest\n",
    "    manifest = pd.DataFrame(manifest_rows)\n",
    "    manifest_path = out_root / \"negative\" / \"negative_patches_manifest.csv\"\n",
    "    manifest.to_csv(manifest_path, index=False)\n",
    "\n",
    "    print(f\"\\n‚úÖ Negative Dataset Complete!\")\n",
    "    print(f\"  Total patches: {len(manifest)}\")\n",
    "    print(f\"  Static shape: ({len(static_vars)}, {tile_size}, {tile_size})\")\n",
    "    print(f\"  Dynamic shape: ({window_days}, {len(dynamic_vars)}, {tile_size}, {tile_size})\")\n",
    "    if aligned_landcover:\n",
    "        print(f\"  Landcover shape: ({num_landcover_classes}, {tile_size}, {tile_size}) [one-hot encoded]\")\n",
    "    print(f\"  Manifest: {manifest_path}\")\n",
    "    print(f\"  Output directory: {out_root / 'negative'}\")\n",
    "\n",
    "    return manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b10a4af-fcfb-4d32-9398-89666299cb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ALIGNED FIRE DATASET BUILDER WITH LANDCOVER\n",
      "======================================================================\n",
      "\n",
      "[Step 0: Discovering Dynamic Rasters]\n",
      "  relative_humidity: found 3656 files\n",
      "  total_precipitation: found 3653 files\n",
      "\n",
      "‚úì Total dynamic files found: 7309\n",
      "\n",
      "[Step 1: Creating Reference Grid]\n",
      "  ‚úì Using existing reference grid: Dataset/Stataic Data/rasters_COP90/elevation_fixed_3310_1000m_clipped.tif\n",
      "\n",
      "[Step 2: Aligning Rasters]\n",
      "‚ö†Ô∏è  This may take a while with ~3,650 dynamic files (10 years √ó 365 days)\n",
      "    Set skip_existing_aligned=True to skip already processed files\n",
      "\n",
      "[Aligning Static Rasters]\n",
      "  ‚úì Using existing: elevation_aligned.tif\n",
      "  ‚úì Using existing: slope_aligned.tif\n",
      "  ‚úì Using existing: population_aligned.tif\n",
      "  ‚úì Using existing: water_proximity_aligned.tif\n",
      "  ‚úì Using existing: road_proximity_aligned.tif\n",
      "\n",
      "[Aligning Landcover Raster]\n",
      "  ‚úì Using existing: landcover_aligned.tif\n",
      "\n",
      "[Aligning Dynamic Rasters]\n",
      "\n",
      "  Processing relative_humidity: 3656 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Aligning relative_humidity: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3656/3656 [00:00<00:00, 84074.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Processing total_precipitation: 3653 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Aligning total_precipitation: 100%|‚ñà‚ñà‚ñà‚ñà| 3653/3653 [00:00<00:00, 97738.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Alignment complete\n",
      "  Static: 5 variables\n",
      "  Dynamic: 7309 files across 2 variables\n",
      "  Landcover: ‚úì Aligned\n",
      "\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "GENERATING NEGATIVE DATASET\n",
      "======================================================================\n",
      "\n",
      "[Step 4: Extracting Negative Fire Patches]\n",
      "  This will create .npy files for patches with NO fire in 10-day window\n",
      "  Sampling 3000 patches per year (2015-2024)\n",
      "\n",
      "[Reference Grid] 915x1056 px\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_7463/4067174254.py:704: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  ca_union = ca.unary_union\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Loading Fire Dataset]\n",
      "  ‚úì Found 4032 fire polygons across 1671 unique dates\n",
      "\n",
      "[Indexing Dynamic Rasters]\n",
      "  relative_humidity: 3653 dates\n",
      "  total_precipitation: 3653 dates\n",
      "  ‚úì 3653 dates available across all dynamic variables\n",
      "\n",
      "[Extracting NEGATIVE Patches]\n",
      "  Static variables: ['elevation', 'population', 'road_proximity', 'slope', 'water_proximity']\n",
      "  Dynamic variables: ['relative_humidity', 'total_precipitation']\n",
      "  Landcover classes: 10\n",
      "  Window days: 10\n",
      "  Samples per year: 1000\n",
      "  Year range: 2015-2024\n",
      "\n",
      "[Pre-computing valid tile positions]\n",
      "  ‚úì Found 24973 valid tile positions inside California\n",
      "\n",
      "[Processing Year 2015]\n",
      "  Valid dates with 10-day window: 356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sampling year 2015: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:15<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Year 2015: Generated 1000 negative samples (attempts: 1000)\n",
      "\n",
      "[Processing Year 2016]\n",
      "  Valid dates with 10-day window: 366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sampling year 2016: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:14<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Year 2016: Generated 1000 negative samples (attempts: 1001)\n",
      "\n",
      "[Processing Year 2017]\n",
      "  Valid dates with 10-day window: 365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sampling year 2017: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:26<00:00, 11.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Year 2017: Generated 1000 negative samples (attempts: 1000)\n",
      "\n",
      "[Processing Year 2018]\n",
      "  Valid dates with 10-day window: 365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sampling year 2018: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:20<00:00, 12.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Year 2018: Generated 1000 negative samples (attempts: 1001)\n",
      "\n",
      "[Processing Year 2019]\n",
      "  Valid dates with 10-day window: 365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sampling year 2019: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:11<00:00, 13.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Year 2019: Generated 1000 negative samples (attempts: 1000)\n",
      "\n",
      "[Processing Year 2020]\n",
      "  Valid dates with 10-day window: 366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sampling year 2020: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:52<00:00,  8.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Year 2020: Generated 1000 negative samples (attempts: 1001)\n",
      "\n",
      "[Processing Year 2021]\n",
      "  Valid dates with 10-day window: 365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sampling year 2021: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [02:08<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Year 2021: Generated 1000 negative samples (attempts: 1002)\n",
      "\n",
      "[Processing Year 2022]\n",
      "  Valid dates with 10-day window: 365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sampling year 2022: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:19<00:00, 12.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Year 2022: Generated 1000 negative samples (attempts: 1001)\n",
      "\n",
      "[Processing Year 2023]\n",
      "  Valid dates with 10-day window: 365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sampling year 2023: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:21<00:00, 12.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Year 2023: Generated 1000 negative samples (attempts: 1001)\n",
      "\n",
      "[Processing Year 2024]\n",
      "  Valid dates with 10-day window: 366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Sampling year 2024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1000/1000 [01:34<00:00, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Year 2024: Generated 1000 negative samples (attempts: 1001)\n",
      "\n",
      "‚úÖ Negative Dataset Complete!\n",
      "  Total patches: 10000\n",
      "  Static shape: (5, 4, 4)\n",
      "  Dynamic shape: (10, 2, 4, 4)\n",
      "  Landcover shape: (10, 4, 4) [one-hot encoded]\n",
      "  Manifest: output_aligned_patches/negative/negative_patches_manifest.csv\n",
      "  Output directory: output_aligned_patches/negative\n",
      "\n",
      "======================================================================\n",
      "üìä NEGATIVE DATASET SUMMARY\n",
      "======================================================================\n",
      "Total negative patches extracted: 10000\n",
      "\n",
      "Static patch shape: (5, 4, 4)\n",
      "Dynamic patch shape: (10, 2, 4, 4)\n",
      "Landcover patch shape: (10, 4, 4) [one-hot encoded]\n",
      "\n",
      "Output directory: output_aligned_patches/negative\n",
      "Manifest file: output_aligned_patches/negative/negative_patches_manifest.csv\n",
      "\n",
      "üìù First few patches:\n",
      "   patch_id                                        static_path  \\\n",
      "0         1  output_aligned_patches/negative/20151123_412_3...   \n",
      "1         2  output_aligned_patches/negative/20150801_172_1...   \n",
      "2         3  output_aligned_patches/negative/20150125_232_5...   \n",
      "3         4  output_aligned_patches/negative/20150419_212_3...   \n",
      "4         5  output_aligned_patches/negative/20151127_924_8...   \n",
      "5         6  output_aligned_patches/negative/20151018_704_6...   \n",
      "6         7  output_aligned_patches/negative/20151227_484_2...   \n",
      "7         8  output_aligned_patches/negative/20150604_1024_...   \n",
      "8         9  output_aligned_patches/negative/20151217_660_5...   \n",
      "9        10  output_aligned_patches/negative/20150124_576_3...   \n",
      "\n",
      "                                        dynamic_path sample_date  year  \\\n",
      "0  output_aligned_patches/negative/20151123_412_3...  2015-11-23  2015   \n",
      "1  output_aligned_patches/negative/20150801_172_1...  2015-08-01  2015   \n",
      "2  output_aligned_patches/negative/20150125_232_5...  2015-01-25  2015   \n",
      "3  output_aligned_patches/negative/20150419_212_3...  2015-04-19  2015   \n",
      "4  output_aligned_patches/negative/20151127_924_8...  2015-11-27  2015   \n",
      "5  output_aligned_patches/negative/20151018_704_6...  2015-10-18  2015   \n",
      "6  output_aligned_patches/negative/20151227_484_2...  2015-12-27  2015   \n",
      "7  output_aligned_patches/negative/20150604_1024_...  2015-06-04  2015   \n",
      "8  output_aligned_patches/negative/20151217_660_5...  2015-12-17  2015   \n",
      "9  output_aligned_patches/negative/20150124_576_3...  2015-01-24  2015   \n",
      "\n",
      "   row_off  col_off           left         bottom          right  \\\n",
      "0      412      340  -34427.210844   34494.774275  -30427.210844   \n",
      "1      172      148 -226427.210844  274494.774275 -222427.210844   \n",
      "2      232       56 -318427.210844  214494.774275 -314427.210844   \n",
      "3      212      352  -22427.210844  234494.774275  -18427.210844   \n",
      "4      924      840  465572.789156 -477505.225725  469572.789156   \n",
      "5      704      692  317572.789156 -257505.225725  321572.789156   \n",
      "6      484      224 -150427.210844  -37505.225725 -146427.210844   \n",
      "7     1024      696  321572.789156 -577505.225725  325572.789156   \n",
      "8      660      580  205572.789156 -213505.225725  209572.789156   \n",
      "9      576      364  -10427.210844 -129505.225725   -6427.210844   \n",
      "\n",
      "             top  label                                        static_vars  \\\n",
      "0   38494.774275      0  elevation,population,road_proximity,slope,wate...   \n",
      "1  278494.774275      0  elevation,population,road_proximity,slope,wate...   \n",
      "2  218494.774275      0  elevation,population,road_proximity,slope,wate...   \n",
      "3  238494.774275      0  elevation,population,road_proximity,slope,wate...   \n",
      "4 -473505.225725      0  elevation,population,road_proximity,slope,wate...   \n",
      "5 -253505.225725      0  elevation,population,road_proximity,slope,wate...   \n",
      "6  -33505.225725      0  elevation,population,road_proximity,slope,wate...   \n",
      "7 -573505.225725      0  elevation,population,road_proximity,slope,wate...   \n",
      "8 -209505.225725      0  elevation,population,road_proximity,slope,wate...   \n",
      "9 -125505.225725      0  elevation,population,road_proximity,slope,wate...   \n",
      "\n",
      "                            dynamic_vars  window_days  \\\n",
      "0  relative_humidity,total_precipitation           10   \n",
      "1  relative_humidity,total_precipitation           10   \n",
      "2  relative_humidity,total_precipitation           10   \n",
      "3  relative_humidity,total_precipitation           10   \n",
      "4  relative_humidity,total_precipitation           10   \n",
      "5  relative_humidity,total_precipitation           10   \n",
      "6  relative_humidity,total_precipitation           10   \n",
      "7  relative_humidity,total_precipitation           10   \n",
      "8  relative_humidity,total_precipitation           10   \n",
      "9  relative_humidity,total_precipitation           10   \n",
      "\n",
      "                                      landcover_path  landcover_classes  \n",
      "0  output_aligned_patches/negative/20151123_412_3...                 10  \n",
      "1  output_aligned_patches/negative/20150801_172_1...                 10  \n",
      "2  output_aligned_patches/negative/20150125_232_5...                 10  \n",
      "3  output_aligned_patches/negative/20150419_212_3...                 10  \n",
      "4  output_aligned_patches/negative/20151127_924_8...                 10  \n",
      "5  output_aligned_patches/negative/20151018_704_6...                 10  \n",
      "6  output_aligned_patches/negative/20151227_484_2...                 10  \n",
      "7  output_aligned_patches/negative/20150604_1024_...                 10  \n",
      "8  output_aligned_patches/negative/20151217_660_5...                 10  \n",
      "9  output_aligned_patches/negative/20150124_576_3...                 10  \n",
      "\n",
      "üìÖ Samples per year:\n",
      "year\n",
      "2015    1000\n",
      "2016    1000\n",
      "2017    1000\n",
      "2018    1000\n",
      "2019    1000\n",
      "2020    1000\n",
      "2021    1000\n",
      "2022    1000\n",
      "2023    1000\n",
      "2024    1000\n",
      "dtype: int64\n",
      "\n",
      "======================================================================\n",
      "üìä SUMMARY\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'manifest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 146\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müìä SUMMARY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    145\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal fire patches extracted: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mmanifest\u001b[49m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    147\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStatic patch shape: (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(aligned_static)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mtile_size\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mtile_size\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    148\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDynamic patch shape: (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mwindow_days\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(aligned_dynamic)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mtile_size\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mtile_size\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'manifest' is not defined"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    'ca_boundary': 'Dataset/Stataic Data/CA_State.gpkg',\n",
    "    'fire_dataset': 'Dataset/Stataic Data/past_fire_2014_2024.gpkg',\n",
    "    'fire_date_field': 'ALARM_DATE',\n",
    "    \n",
    "    'static_rasters': {\n",
    "        'elevation': 'Dataset/Stataic Data/rasters_COP90/output_hh.tif',\n",
    "        'slope': 'Dataset/Stataic Data/viz/Slope.tif',\n",
    "        'population': 'Dataset/Stataic Data/Population/mosaic_masked.tif',\n",
    "        'water_proximity': 'Dataset/Stataic Data/Waterway/ca_water_distance.tif',\n",
    "        'road_proximity': 'Dataset/Stataic Data/roadways/ca_road_distance_snapped.tif',\n",
    "    },\n",
    "    'landcover_raster': 'Dataset/Stataic Data/LandCover/land_cover_cal_reclass.tif', \n",
    "    \n",
    "    'dynamic_folders': {\n",
    "        'relative_humidity': 'Dataset/Dynamic Data/relative_humidity',\n",
    "        'total_precipitation': 'Dataset/Dynamic Data/Precipitation',\n",
    "    },\n",
    "    'reference_grid_path': 'Dataset/Stataic Data/rasters_COP90/elevation_fixed_3310_1000m_clipped.tif',\n",
    "    'out_root': 'output_aligned_patches',\n",
    "    'tile_size': 4,\n",
    "    'window_days': 10,  \n",
    "    'dst_crs': 'EPSG:3310',\n",
    "    'dst_res': 1000.0,  \n",
    "    'skip_existing_aligned': True,  \n",
    "    'min_pos_frac': 0.10,  \n",
    "    'require_all_valid': False,\n",
    "    'num_landcover_classes': 10,\n",
    "    'write_individual_landcover_tifs': True,\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ALIGNED FIRE DATASET BUILDER WITH LANDCOVER\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[Step 0: Discovering Dynamic Rasters]\")\n",
    "dynamic_rasters = discover_dynamic_rasters(\n",
    "    dynamic_folders=config['dynamic_folders'],\n",
    "    pattern=\"*.tif\"\n",
    ")\n",
    "print(f\"\\n‚úì Total dynamic files found: {sum(len(files) for files in dynamic_rasters.values())}\")\n",
    "\n",
    "print(\"\\n[Step 1: Creating Reference Grid]\")\n",
    "if os.path.exists(config['reference_grid_path']):\n",
    "    print(f\"  ‚úì Using existing reference grid: {config['reference_grid_path']}\")\n",
    "    ref_grid = config['reference_grid_path']\n",
    "else:\n",
    "    ref_grid = create_reference_grid(\n",
    "        ca_boundary=config['ca_boundary'],\n",
    "        out_path=config['reference_grid_path'],\n",
    "        dst_crs=config['dst_crs'],\n",
    "        dst_res=config['dst_res']\n",
    "    )\n",
    "\n",
    "print(\"\\n[Step 2: Aligning Rasters]\")\n",
    "print(\"‚ö†Ô∏è  This may take a while with ~3,650 dynamic files (10 years √ó 365 days)\")\n",
    "print(\"    Set skip_existing_aligned=True to skip already processed files\")\n",
    "aligned_static, aligned_dynamic, aligned_landcover = align_all_rasters(\n",
    "    static_rasters=config['static_rasters'],\n",
    "    dynamic_rasters=dynamic_rasters,\n",
    "    landcover_raster=config.get('landcover_raster'),  # NEW\n",
    "    reference_grid=ref_grid,\n",
    "    ca_boundary=config['ca_boundary'],\n",
    "    out_root=config['out_root'],\n",
    "    skip_existing=config['skip_existing_aligned']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Alignment complete\")\n",
    "print(f\"  Static: {len(aligned_static)} variables\")\n",
    "print(f\"  Dynamic: {sum(len(files) for files in aligned_dynamic.values())} files across {len(aligned_dynamic)} variables\")\n",
    "if aligned_landcover:\n",
    "    print(f\"  Landcover: ‚úì Aligned\")\n",
    "\n",
    "# print(\"\\n[Step 3: Extracting Aligned Fire Patches]\")\n",
    "# print(\"  This will create .npy files for patches that overlap with fires\")\n",
    "# manifest = build_aligned_fire_dataset(\n",
    "#     aligned_static=aligned_static,\n",
    "#     aligned_dynamic=aligned_dynamic,\n",
    "#     aligned_landcover=aligned_landcover,  # NEW\n",
    "#     fire_dataset=config['fire_dataset'],\n",
    "#     fire_date_field=config['fire_date_field'],\n",
    "#     ca_boundary=config['ca_boundary'],\n",
    "#     out_root=config['out_root'],\n",
    "#     tile_size=config['tile_size'],\n",
    "#     window_days=config['window_days'],\n",
    "#     min_pos_frac=config['min_pos_frac'],\n",
    "#     require_all_valid=config['require_all_valid'],\n",
    "#     num_landcover_classes=config.get('num_landcover_classes', 10),  # NEW\n",
    "#     write_individual_landcover_tifs=config.get('write_individual_landcover_tifs', True),  # NEW\n",
    "# )\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "\n",
    "# =========================================================================\n",
    "# STEP 4: Generate Negative Dataset (No Fire Samples)\n",
    "# =========================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATING NEGATIVE DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[Step 4: Extracting Negative Fire Patches]\")\n",
    "print(\"  This will create .npy files for patches with NO fire in 10-day window\")\n",
    "print(\"  Sampling 3000 patches per year (2015-2024)\")\n",
    "\n",
    "negative_manifest = build_negative_fire_dataset(\n",
    "    aligned_static=aligned_static,\n",
    "    aligned_dynamic=aligned_dynamic,\n",
    "    aligned_landcover=aligned_landcover,\n",
    "    fire_dataset=config['fire_dataset'],\n",
    "    fire_date_field=config['fire_date_field'],\n",
    "    ca_boundary=config['ca_boundary'],\n",
    "    out_root=config['out_root'],\n",
    "    tile_size=config['tile_size'],\n",
    "    window_days=config['window_days'],\n",
    "    samples_per_year=1000,\n",
    "    min_valid_frac=config.get('min_valid_frac', 0.50),\n",
    "    require_all_valid=config['require_all_valid'],\n",
    "    num_landcover_classes=config.get('num_landcover_classes', 10),\n",
    "    start_year=2015,\n",
    "    end_year=2024,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä NEGATIVE DATASET SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total negative patches extracted: {len(negative_manifest)}\")\n",
    "print(f\"\\nStatic patch shape: ({len(aligned_static)}, {config['tile_size']}, {config['tile_size']})\")\n",
    "print(f\"Dynamic patch shape: ({config['window_days']}, {len(aligned_dynamic)}, {config['tile_size']}, {config['tile_size']})\")\n",
    "if aligned_landcover:\n",
    "    print(f\"Landcover patch shape: ({config['num_landcover_classes']}, {config['tile_size']}, {config['tile_size']}) [one-hot encoded]\")\n",
    "\n",
    "print(f\"\\nOutput directory: {config['out_root']}/negative\")\n",
    "print(f\"Manifest file: {config['out_root']}/negative/negative_patches_manifest.csv\")\n",
    "\n",
    "if len(negative_manifest) > 0:\n",
    "    print(f\"\\nüìù First few patches:\")\n",
    "    print(negative_manifest.head(10))\n",
    "    \n",
    "    print(f\"\\nüìÖ Samples per year:\")\n",
    "    print(negative_manifest.groupby('year').size())\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total fire patches extracted: {len(manifest)}\")\n",
    "print(f\"\\nStatic patch shape: ({len(aligned_static)}, {config['tile_size']}, {config['tile_size']})\")\n",
    "print(f\"Dynamic patch shape: ({config['window_days']}, {len(aligned_dynamic)}, {config['tile_size']}, {config['tile_size']})\")\n",
    "if aligned_landcover:\n",
    "    print(f\"Landcover patch shape: ({config['num_landcover_classes']}, {config['tile_size']}, {config['tile_size']}) [one-hot encoded]\")\n",
    "\n",
    "print(f\"\\nOutput directory: {config['out_root']}\")\n",
    "print(f\"Manifest file: {config['out_root']}/aligned_patches_manifest.csv\")\n",
    "\n",
    "if len(manifest) > 0:\n",
    "    print(f\"\\nüìù First few patches:\")\n",
    "    print(manifest.head(10))\n",
    "    \n",
    "    print(f\"\\nüìÖ Date range:\")\n",
    "    print(f\"  Earliest: {manifest['fire_date'].min()}\")\n",
    "    print(f\"  Latest: {manifest['fire_date'].max()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
